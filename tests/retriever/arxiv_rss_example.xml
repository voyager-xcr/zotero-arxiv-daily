<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns="http://www.w3.org/2005/Atom" xml:lang="en-us">
  <id>http://rss.arxiv.org/atom/cs.AI</id>
  <title>cs.AI updates on arXiv.org</title>
  <updated>2025-08-20T04:00:19.866337+00:00</updated>
  <link href="http://rss.arxiv.org/atom/cs.AI" rel="self" type="application/atom+xml"/>
  <subtitle>cs.AI updates on the arXiv.org e-print archive.</subtitle>
  <entry>
    <id>oai:arXiv.org:2508.13167v1</id>
    <title>Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL</title>
    <updated>2025-08-20T04:00:19.910019+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13167" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13167v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) and multi-agent systems have demonstrated remarkable capabilities in complex problem-solving tasks such as deep research, vibe coding, and mathematical reasoning. However, most existing multi-agent systems are built upon manual prompt/workflow engineering with sophisticated agent frameworks, making them computationally inefficient, less capable, and can not benefit from data-centric learning. In this work, we introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables native end-to-end complex problem-solving in the same way as a multi-agent system (i.e., multi-turn problem solving with multiple tools and multiple agents) within one model. In chain-of-agents problem-solving, the model dynamically activates different tool agents and role-playing agents to simulate multi-agent collaboration in an end-to-end fashion. To elicit end-to-end chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent distillation framework to distill state-of-the-art multi-agent systems into chain-of-agents trajectories for agentic supervised fine-tuning. We then use agentic reinforcement learning on verifiable agentic tasks to further improve the models' capabilities on chain-of-agents problem solving. We call the resulting models Agent Foundation Models (AFMs). Our empirical studies demonstrate that AFM establishes new state-of-the-art performance across diverse benchmarks in both web agent and code agent settings. We make the entire research, including the model weights, code for training and evaluation, and the training data, fully open-sourced, which offers a solid starting point for future research on agent models and agentic RL.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <dc:creator>Weizhen Li, Jianbo Lin, Zhuosong Jiang, Jingyi Cao, Xinpeng Liu, Jiayu Zhang, Zhenqiang Huang, Qianben Chen, Weichen Sun, Qiexiang Wang, Hongxuan Lu, Tianrui Qin, Chenghao Zhu, Yi Yao, Shuying Fan, Xiaowan Li, Tiannan Wang, Pai Liu, King Zhu, He Zhu, Dingfeng Shi, Piaohong Wang, Yeyi Guan, Xiangru Tang, Minghao Liu, Yuchen Eleanor Jiang, Jian Yang, Jiaheng Liu, Ge Zhang, Wangchunshu Zhou</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13171v1</id>
    <title>Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context</title>
    <updated>2025-08-20T04:00:19.909947+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13171" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13171v1 Announce Type: new 
Abstract: Large Language Models (LLMs) face fundamental limitations in context management despite recent advances extending context windows to millions of tokens. We propose Cognitive Workspace, a novel paradigm that transcends traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive mechanisms of external memory use. Drawing from cognitive science foundations including Baddeley's working memory model, Clark's extended mind thesis, and Hutchins' distributed cognition framework, we demonstrate that current passive retrieval systems fail to capture the dynamic, task-driven nature of human memory management. Our analysis of 2024-2025 developments reveals that while techniques like Infini-attention and StreamingLLM achieve impressive context lengths, they lack the metacognitive awareness and active planning capabilities essential for true cognitive extension. Cognitive Workspace addresses these limitations through three core innovations: (1) active memory management with deliberate information curation, (2) hierarchical cognitive buffers enabling persistent working states, and (3) task-driven context optimization that dynamically adapts to cognitive demands. Empirical validation demonstrates Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from 54-60% across different tasks) compared to 0% for traditional RAG, with 17-18% net efficiency gain despite 3.3x higher operation counts. Statistical analysis confirms these advantages with p &lt; 0.001 and Cohen's d &gt; 23 across multiple task types, establishing the first quantitative evidence for active memory superiority in LLM systems. We present a comprehensive theoretical framework synthesizing insights from 50+ recent papers, positioning Cognitive Workspace as a fundamental shift from information retrieval to genuine cognitive augmentation.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Tao An</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13174v1</id>
    <title>AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining</title>
    <updated>2025-08-20T04:00:19.909880+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13174" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13174v1 Announce Type: new 
Abstract: Formula alpha mining, which generates predictive signals from financial data, is critical for quantitative investment. Although various algorithmic approaches-such as genetic programming, reinforcement learning, and large language models-have significantly expanded the capacity for alpha discovery, systematic evaluation remains a key challenge. Existing evaluation metrics predominantly include backtesting and correlation-based measures. Backtesting is computationally intensive, inherently sequential, and sensitive to specific strategy parameters. Correlation-based metrics, though efficient, assess only predictive ability and overlook other crucial properties such as temporal stability, robustness, diversity, and interpretability. Additionally, the closed-source nature of most existing alpha mining models hinders reproducibility and slows progress in this field. To address these issues, we propose AlphaEval, a unified, parallelizable, and backtest-free evaluation framework for automated alpha mining models. AlphaEval assesses the overall quality of generated alphas along five complementary dimensions: predictive power, stability, robustness to market perturbations, financial logic, and diversity. Extensive experiments across representative alpha mining algorithms demonstrate that AlphaEval achieves evaluation consistency comparable to comprehensive backtesting, while providing more comprehensive insights and higher efficiency. Furthermore, AlphaEval effectively identifies superior alphas compared to traditional single-metric screening approaches. All implementations and evaluation tools are open-sourced to promote reproducibility and community engagement.</summary>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <category term="q-fin.CP"/>
    <category term="stat.ML"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Hongjun Ding, Binqi Chen, Jinsheng Huang, Taian Guo, Zhengyang Mao, Guoyi Shao, Lutong Zou, Luchen Liu, Ming Zhang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13176v1</id>
    <title>Fitting Ontologies and Constraints to Relational Structures</title>
    <updated>2025-08-20T04:00:19.909810+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13176" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13176v1 Announce Type: new 
Abstract: We study the problem of fitting ontologies and constraints to positive and negative examples that take the form of a finite relational structure. As ontology and constraint languages, we consider the description logics $\mathcal{E\mkern-2mu L}$ and $\mathcal{E\mkern-2mu LI}$ as well as several classes of tuple-generating dependencies (TGDs): full, guarded, frontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion dependencies. We pinpoint the exact computational complexity, design algorithms, and analyze the size of fitting ontologies and TGDs. We also investigate the related problem of constructing a finite basis of concept inclusions / TGDs for a given set of finite structures. While finite bases exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs, and inclusion dependencies, they in general do not exist for full, frontier-guarded and frontier-one TGDs.</summary>
    <category term="cs.AI"/>
    <category term="cs.DB"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Simon Hosemann, Jean Christoph Jung, Carsten Lutz, Sebastian Rudolph</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13177v1</id>
    <title>A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment</title>
    <updated>2025-08-20T04:00:19.909730+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13177" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13177v1 Announce Type: new 
Abstract: Active Inference (AIF) offers a robust framework for decision-making, yet its computational and memory demands pose challenges for deployment, especially in resource-constrained environments. This work presents a methodology that facilitates AIF's deployment by integrating pymdp's flexibility and efficiency with a unified, sparse, computational graph tailored for hardware-efficient execution. Our approach reduces latency by over 2x and memory by up to 35%, advancing the deployment of efficient AIF agents for real-time and embedded applications.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Nikola Pi\v{z}urica, Nikola Milovi\'c, Igor Jovan\v{c}evi\'c, Conor Heins, Miguel de Prado</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13178v1</id>
    <title>The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task</title>
    <updated>2025-08-20T04:00:19.909653+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13178" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13178v1 Announce Type: new 
Abstract: To elevate the foundational capabilities and generalization prowess of the text-to-SQL model in real-world applications, we integrate model interpretability analysis with execution-guided strategy for semantic parsing of WHERE clauses in SQL queries. Furthermore, we augment this approach with filtering adjustments, logical correlation refinements, and model fusion, culminating in the design of the CESQL model that facilitates conditional enhancement. Our model excels on the WikiSQL dataset, which is emblematic of single-table database query tasks, markedly boosting the accuracy of prediction outcomes. When predicting conditional values in WHERE clauses, we have not only minimized our dependence on data within the condition columns of tables but also circumvented the impact of manually labeled training data. Our hope is that this endeavor to enhance accuracy in processing basic database queries will offer fresh perspectives for research into handling complex queries and scenarios featuring irregular data in real-world database environments.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <category term="cs.DB"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Cong Zhang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13180v1</id>
    <title>Search-Time Data Contamination</title>
    <updated>2025-08-20T04:00:19.909574+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13180" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13180v1 Announce Type: new 
Abstract: Data contamination refers to the leakage of evaluation data into model training data, resulting in overfitting to supposedly held-out test sets and compromising test validity. We identify an analogous issue, search-time contamination (STC), in evaluating search-based LLM agents which use tools to gather information from online sources when answering user queries. STC occurs when the retrieval step surfaces a source containing the test question (or a near-duplicate) alongside its answer, enabling agents to copy rather than genuinely infer or reason, undermining benchmark integrity. We find that HuggingFace, an online platform hosting evaluation datasets, appears among retrieved sources in search based agent logs. Consequently, agents often explicitly acknowledge discovering question answer pairs from HuggingFace within their reasoning chains. On three commonly used capability benchmarks: Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for approximately 3% of questions, search-based agents directly find the datasets with ground truth labels on HuggingFace. When millions of evaluation queries target the same benchmark, even small, repeated leaks can accelerate the benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace is blocked, we observe a drop in accuracy on the contaminated subset of approximately 15%. We further show through ablation experiments that publicly accessible evaluation datasets on HuggingFace may not be the sole source of STC. To this end, we conclude by proposing best practices for benchmark design and result reporting to address this novel form of leakage and ensure trustworthy evaluation of search-based LLM agents. To facilitate the auditing of evaluation results, we also publicly release the complete logs from our experiments.</summary>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
    <dc:creator>Ziwen Han, Meher Mankikar, Julian Michael, Zifan Wang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13204v1</id>
    <title>QuickMerge++: Fast Token Merging with Autoregressive Prior</title>
    <updated>2025-08-20T04:00:19.909501+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13204" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13204v1 Announce Type: new 
Abstract: As generative models scale to larger inputs across language, vision, and video domains, the cost of token-level computation has become a key bottleneck. While prior work suggests that only a subset of tokens significantly influence downstream predictions, most token selection methods are static, modality-specific, or incompatible with autoregressive generation. In this paper, we propose QuickMerge, a lightweight token merging framework designed for efficient next-token prediction.
  QuickMerge dynamically selects a reduced number of tokens based on attention norm magnitude, guided by an entropy-based budget estimator. To preserve autoregressive compatibility, we introduce a lightweight transformer prior trained over the merged token sequence. By combining semantic salience estimation, flexible token budgets, and AR alignment, QuickMerge enables accurate generation with fewer tokens.
  We evaluate QuickMerge across multi-modality domains, demonstrating consistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge reduces token counts sustantially while matching as well as exceeding the performance of learned tokenizers and fixed-patch baselines.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Dong Liu, Yanxuan Yu</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13213v1</id>
    <title>AI sustains higher strategic tension than humans in chess</title>
    <updated>2025-08-20T04:00:19.909432+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13213" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13213v1 Announce Type: new 
Abstract: Strategic decision-making involves managing the tension between immediate opportunities and long-term objectives. We study this trade-off in chess by characterizing and comparing dynamics between human vs human and AI vs AI games. We propose a network-based metric of piece-to-piece interaction to quantify the ongoing strategic tension on the board. Its evolution in games reveals that the most competitive AI players sustain higher levels of strategic tension for longer durations than elite human players. Cumulative tension varies with algorithmic complexity for AI and correspondingly in human-played games increases abruptly with expertise at about 1600 Elo and again at 2300 Elo. The profiles reveal different approaches. Highly competitive AI tolerates interconnected positions balanced between offensive and defensive tactics over long periods. Human play, in contrast, limits tension and game complexity, which may reflect cognitive limitations and adaptive strategies. The difference may have implications for AI usage in complex, strategic environments.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Adamo Cerioli, Edward D. Lee, Vito D. P. Servedio</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13250v1</id>
    <title>Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information</title>
    <updated>2025-08-20T04:00:19.909365+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13250" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13250v1 Announce Type: new 
Abstract: In large language model-based agents, memory serves as a critical capability for achieving personalization by storing and utilizing users' information. Although some previous studies have adopted memory to implement user personalization, they typically focus on preference alignment and simple question-answering. However, in the real world, complex tasks often require multi-hop reasoning on a large amount of user information, which poses significant challenges for current memory approaches. To address this limitation, we propose the multi-hop personalized reasoning task to explore how different memory mechanisms perform in multi-hop reasoning over personalized information. We explicitly define this task and construct a dataset along with a unified evaluation framework. Then, we implement various explicit and implicit memory methods and conduct comprehensive experiments. We evaluate their performance on this task from multiple perspectives and analyze their strengths and weaknesses. Besides, we explore hybrid approaches that combine both paradigms and propose the HybridMem method to address their limitations. We demonstrate the effectiveness of our proposed model through extensive experiments. To benefit the research community, we release this project at https://github.com/nuster1128/MPR.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <category term="cs.IR"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Zeyu Zhang, Yang Zhang, Haoran Tan, Rui Li, Xu Chen</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13251v1</id>
    <title>"DIVE" into Hydrogen Storage Materials Discovery with AI Agents</title>
    <updated>2025-08-20T04:00:19.909297+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13251" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13251v1 Announce Type: new 
Abstract: Data-driven artificial intelligence (AI) approaches are fundamentally transforming the discovery of new materials. Despite the unprecedented availability of materials data in the scientific literature, much of this information remains trapped in unstructured figures and tables, hindering the construction of large language model (LLM)-based AI agent for automated materials design. Here, we present the Descriptive Interpretation of Visual Expression (DIVE) multi-agent workflow, which systematically reads and organizes experimental data from graphical elements in scientific literatures. We focus on solid-state hydrogen storage materials-a class of materials central to future clean-energy technologies and demonstrate that DIVE markedly improves the accuracy and coverage of data extraction compared to the direct extraction by multimodal models, with gains of 10-15% over commercial models and over 30% relative to open-source models. Building on a curated database of over 30,000 entries from 4,000 publications, we establish a rapid inverse design workflow capable of identifying previously unreported hydrogen storage compositions in two minutes. The proposed AI workflow and agent design are broadly transferable across diverse materials, providing a paradigm for AI-driven materials discovery.</summary>
    <category term="cs.AI"/>
    <category term="cond-mat.mtrl-sci"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <dc:creator>Di Zhang, Xue Jia, Tran Ba Hung, Seong Hoon Jang, Linda Zhang, Ryuhei Sato, Yusuke Hashimoto, Toyoto Sato, Kiyoe Konno, Shin-ichi Orimo, Hao Li</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13256v1</id>
    <title>CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support</title>
    <updated>2025-08-20T04:00:19.909236+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13256" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13256v1 Announce Type: new 
Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality worldwide, a burden worsened by a severe deficit of healthcare workers. Artificial intelligence (AI) agents have shown potential to alleviate this gap via automated early detection and proactive screening, yet their clinical application remains limited by: 1) prompt-based clinical role assignment that relies on intrinsic model capabilities without domain-specific tool support; or 2) rigid sequential workflows, whereas clinical care often requires adaptive reasoning that orders specific tests and, based on their results, guides personalised next steps; 3) general and static knowledge bases without continuous learning capability; and 4) fixed unimodal or bimodal inputs and lack of on-demand visual outputs when further clarification is needed. In response, a multimodal framework, CardAIc-Agents, was proposed to augment models with external tools and adaptively support diverse cardiac tasks. Specifically, a CardiacRAG agent generated general plans from updatable cardiac knowledge, while the chief agent integrated tools to autonomously execute these plans and deliver decisions. To enable adaptive and case-specific customization, a stepwise update strategy was proposed to dynamically refine plans based on preceding execution results, once the task was assessed as complex. In addition, a multidisciplinary discussion tool was introduced to interpret challenging cases, thereby supporting further adaptation. When clinicians raised concerns, visual review panels were provided to assist final validation. Experiments across three datasets showed the efficiency of CardAIc-Agents compared to mainstream Vision-Language Models (VLMs), state-of-the-art agentic systems, and fine-tuned VLMs.</summary>
    <category term="cs.AI"/>
    <category term="cs.CY"/>
    <category term="cs.MA"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yuting Zhang, Karina V. Bunting, Asgher Champsi, Xiaoxia Wang, Wenqi Lu, Alexander Thorley, Sandeep S Hothi, Zhaowen Qiu, Dipak Kotecha, Jinming Duan</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13327v1</id>
    <title>Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention</title>
    <updated>2025-08-20T04:00:19.909180+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13327" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13327v1 Announce Type: new 
Abstract: We propose STONK (Stock Optimization using News Knowledge), a multimodal framework integrating numerical market indicators with sentiment-enriched news embeddings to improve daily stock-movement prediction. By combining numerical &amp; textual embeddings via feature concatenation and cross-modal attention, our unified pipeline addresses limitations of isolated analyses. Backtesting shows STONK outperforms numeric-only baselines. A comprehensive evaluation of fusion strategies and model configurations offers evidence-based guidance for scalable multimodal financial forecasting. Source code is available on GitHub</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Sarthak Khanna, Armin Berger, David Berghaus, Tobias Deusser, Lorenz Sparrenberg, Rafet Sifa</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13333v1</id>
    <title>HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design</title>
    <updated>2025-08-20T04:00:19.909111+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13333" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13333v1 Announce Type: new 
Abstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation (EC) frameworks has shown promising results. However, its effectiveness is hindered by the use of static operators and the lack of knowledge accumulation mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two synergistic prompting strategies: Foresight and Hindsight. Foresight-based prompts adaptively steer the search based on population dynamics, managing the exploration-exploitation trade-off. In addition, hindsight-based prompts mimic human expertise by distilling successful heuristics from past generations into fundamental, reusable design principles. This dual mechanism transforms transient discoveries into a persistent knowledge base, enabling the LLM to learn from its own experience. Empirical results demonstrate that HiFo-Prompt significantly outperforms state-of-the-art LLM-based AHD methods, generating higher-quality heuristics while achieving substantially faster convergence and superior query efficiency.</summary>
    <category term="cs.AI"/>
    <category term="cs.NE"/>
    <category term="math.OC"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Chentong Chen, Mengyuan Zhong, Jianyong Sun, Ye Fan, Jialong Shi</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13371v1</id>
    <title>LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems</title>
    <updated>2025-08-20T04:00:19.908998+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13371" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13371v1 Announce Type: new 
Abstract: Planning is one of the most critical tasks in autonomous systems, where even a small error can lead to major failures or million-dollar losses. Current state-of-the-art neural planning approaches struggle with complex domains, producing plans with missing preconditions, inconsistent goals, and hallucinations. While classical planners provide logical guarantees, they lack the flexibility and natural language understanding capabilities needed for modern autonomous systems. Existing neuro-symbolic approaches use one-shot translation from natural language to formal plans, missing the opportunity for neural and symbolic components to work and refine solutions together. To address this gap, we develop LOOP -- a novel neuro-symbolic planning framework that treats planning as an iterative conversation between neural and symbolic components rather than simple translation. LOOP integrates 13 coordinated neural features including graph neural networks for spatial relationships, multi-agent validation for consensus-based correctness, hierarchical decomposition for complex task management, and causal memory that learns from both successes and failures. Unlike existing approaches, LOOP generates PDDL specifications, refines them iteratively based on symbolic feedback, and builds a causal knowledge base from execution traces. LOOP was evaluated on six standard IPC benchmark domains, where it achieved 85.8% success rate compared to LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This work shows that the key to reliable planning is not in choosing between neural networks or symbolic reasoners but it lies in making them actually ``talk'' to each other during the entire process. LOOP provides a thorough blueprint for building autonomous systems that can finally be trusted with critical real-world applications.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Ronit Virwani, Ruchika Suryawanshi</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13387v1</id>
    <title>SPANER: Shared Prompt Aligner for Multimodal Semantic Representation</title>
    <updated>2025-08-20T04:00:19.908941+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13387" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13387v1 Announce Type: new 
Abstract: Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have significantly improved performance on downstream tasks such as few-shot retrieval. However, most existing approaches focus on task-specific gains while neglecting the structure of the multimodal embedding space. As a result, modality-specific representations often remain isolated, limiting cross-modal generalisation. In this work, we introduce Shared Prompt AligNER (SPANER), a modality-agnostic PEFT framework designed to embed inputs from diverse modalities into a unified semantic space. At its core, SPANER employs a shared prompt mechanism that acts as a conceptual anchor, enabling semantically related instances to converge spatially regardless of modality. This shared prompt design is inherently extensible, supporting the seamless integration of additional modalities, such as audio, without altering the core architecture. Through comprehensive experiments across vision-language and audio-visual benchmarks, SPANER demonstrates competitive few-shot retrieval performance while preserving high semantic coherence in the learned embedding space. Our results highlight the importance of aligning embedding structures, rather than merely tuning adapter weights, for scalable multimodal learning.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Thye Shan Ng, Caren Soyeon Han, Eun-Jung Holden</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13404v1</id>
    <title>TASER: Table Agents for Schema-guided Extraction and Recommendation</title>
    <updated>2025-08-20T04:00:19.908877+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13404" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13404v1 Announce Type: new 
Abstract: Real-world financial documents report essential information about an entity's financial holdings that can span millions of different financial instrument types. Yet, these details are often buried in messy, multi-page, fragmented tables - for example, 99.4% of the tables in our dataset have no bounding boxes with the maximum number of rows amounting to 426 per table across 44 pages. To tackle these unique challenges from real-world tables, we present a continuously learning, agentic table extraction system, TASER (Table Agents for Schema-guided Extraction and Recommendation) that extracts highly unstructured, multi-page, heterogeneous tables into normalized, schema-conforming outputs. Our table agents execute on table detection, classification, extraction, and recommendations by leveraging an initial schema. Then, our Recommender Agent reviews the outputs, recommends schema revisions, and decides on the final recommendations, enabling TASER to outperform existing table detection models such as Table Transformer by 10.1%. Within this continuous learning process, we highlight that larger batch sizes result in a 104.3% increase in schema recommendations that are actionable and utilized, resulting in a 9.8% increase in extracted holdings - highlighting the importance of a continuous learning process. To train TASER, we have manually labeled 22,584 pages (28,150,449 tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of the first real financial table datasets. We release our dataset TASERTab to enable the research community to access real-world financial tables and outputs. Our results highlight the promise of agentic, schema-guided extraction systems for robust understanding of real-world financial tables.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <category term="cs.IR"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Nicole Cho, Kirsty Fielding, William Watson, Sumitra Ganesh, Manuela Veloso</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13421v1</id>
    <title>Virtuous Machines: Towards Artificial General Science</title>
    <updated>2025-08-20T04:00:19.908815+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13421" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13421v1 Announce Type: new 
Abstract: Artificial intelligence systems are transforming scientific discovery by accelerating specific research tasks, from protein structure prediction to materials design, yet remain confined to narrow domains requiring substantial human oversight. The exponential growth of scientific literature and increasing domain specialisation constrain researchers' capacity to synthesise knowledge across disciplines and develop unifying theories, motivating exploration of more general-purpose AI systems for science. Here we show that a domain-agnostic, agentic AI system can independently navigate the scientific workflow - from hypothesis generation through data collection to manuscript preparation. The system autonomously designed and executed three psychological studies on visual working memory, mental rotation, and imagery vividness, executed one new online data collection with 288 participants, developed analysis pipelines through 8-hour+ continuous coding sessions, and produced completed manuscripts. The results demonstrate the capability of AI scientific discovery pipelines to conduct non-trivial research with theoretical reasoning and methodological rigour comparable to experienced researchers, though with limitations in conceptual nuance and theoretical interpretation. This is a step toward embodied AI that can test hypotheses through real-world experiments, accelerating discovery by autonomously exploring regions of scientific space that human cognitive and resource constraints might otherwise leave unexplored. It raises important questions about the nature of scientific understanding and the attribution of scientific credit.</summary>
    <category term="cs.AI"/>
    <category term="cs.ET"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Gabrielle Wehr, Reuben Rideaux, Amaya J. Fox, David R. Lightfoot, Jason Tangen, Jason B. Mattingley, Shane E. Ehrhardt</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13433v1</id>
    <title>STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting</title>
    <updated>2025-08-20T04:00:19.908754+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13433" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13433v1 Announce Type: new 
Abstract: Spatio-temporal traffic forecasting is challenging due to complex temporal patterns, dynamic spatial structures, and diverse input formats. Although Transformer-based models offer strong global modeling, they often struggle with rigid temporal encoding and weak space-time fusion. We propose STPFormer, a Spatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art performance via unified and interpretable representation learning. It integrates four modules: Temporal Position Aggregator (TPA) for pattern-aware temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial learning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment, and an Attention Mixer for multi-scale fusion. Experiments on five real-world datasets show that STPFormer consistently sets new SOTA results, with ablation and visualizations confirming its effectiveness and generalizability.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Jiayu Fang, Zhiqi Shao, S T Boris Choy, Junbin Gao</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13437v1</id>
    <title>Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences</title>
    <updated>2025-08-20T04:00:19.908690+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13437" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13437v1 Announce Type: new 
Abstract: We introduce the Discrete Min-Max Violation (DMMV) as a general optimization problem which seeks an assignment of discrete values to variables that minimizes the largest constraint violation. This context-free mathematical formulation is applicable to a wide range of use cases that have worst-case performance requirements. After defining the DMMV problem mathematically, we explore its properties to establish a foundational understanding. To tackle DMMV instance sizes of practical relevance, we develop a GPU-accelerated heuristic that takes advantage of the mathematical properties of DMMV for speeding up the solution process. We demonstrate the versatile applicability of our heuristic by solving three optimization problems as use cases: (1) post-training quantization of language models, (2) discrete tomography, and (3) Finite Impulse Response (FIR) filter design. In quantization without outlier separation, our heuristic achieves 14% improvement on average over existing methods. In discrete tomography, it reduces reconstruction error by 16% under uniform noise and accelerates computations by a factor of 6 on GPU. For FIR filter design, it nearly achieves 50% ripple reduction compared to using the commercial integer optimization solver, Gurobi. Our comparative results point to the benefits of studying DMMV as a context-free optimization problem and the advantages that our proposed heuristic offers on three distinct problems. Our GPU-accelerated heuristic will be made open-source to further stimulate research on DMMV and its other applications. The code is available at https://anonymous.4open.science/r/AMVM-5F3E/</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Cheikh Ahmed, Mahdi Mostajabdaveh, Samin Aref, Zirui Zhou</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13465v1</id>
    <title>LM Agents May Fail to Act on Their Own Risk Knowledge</title>
    <updated>2025-08-20T04:00:19.908616+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13465" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13465v1 Announce Type: new 
Abstract: Language model (LM) agents have demonstrated significant potential for automating real-world tasks, yet they pose a diverse array of potential, severe risks in safety-critical scenarios. In this work, we identify a significant gap between LM agents' risk awareness and safety execution abilities: while they often answer "Yes" to queries like "Is executing `sudo rm -rf /*' dangerous?", they will likely fail to identify such risks in instantiated trajectories or even directly perform these risky actions when acting as agents. To systematically investigate this, we develop a comprehensive evaluation framework to examine agents' safety across three progressive dimensions: 1) their knowledge about potential risks, 2) their ability to identify corresponding risks in execution trajectories, and 3) their actual behaviors to avoid executing these risky actions. Our evaluation reveals two critical performance gaps that resemble the generator-validator gaps observed in LMs: while agents demonstrate near-perfect risk knowledge ($&gt;98\%$ pass rates), they fail to apply this knowledge when identifying risks in actual scenarios (with performance dropping by $&gt;23\%$) and often still execute risky actions ($&lt;26\%$ pass rates). Notably, this trend persists across more capable LMs as well as in specialized reasoning models like DeepSeek-R1, indicating that simply scaling model capabilities or inference compute does not inherently resolve safety concerns. Instead, we take advantage of these observed gaps to develop a risk verifier that independently critiques the proposed actions by agents, with an abstractor that converts specific execution trajectories into abstract descriptions where LMs can more effectively identify the risks. Our overall system achieves a significant reduction of risky action execution by $55.3\%$ over vanilla-prompted agents.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yuzhi Tang, Tianxiao Li, Elizabeth Li, Chris J. Maddison, Honghua Dong, Yangjun Ruan</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13530v1</id>
    <title>CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter</title>
    <updated>2025-08-20T04:00:19.908419+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13530" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13530v1 Announce Type: new 
Abstract: Developing general-purpose embodied agents is a core challenge in AI. Minecraft provides rich complexity and internet-scale data, but its slow speed and engineering overhead make it unsuitable for rapid prototyping. Crafter offers a lightweight alternative that retains key challenges from Minecraft, yet its use has remained limited to narrow tasks due to the absence of foundation models that have driven progress in the Minecraft setting. In this paper, we present CrafterDojo, a suite of foundation models and tools that unlock the Crafter environment as a lightweight, prototyping-friendly, and Minecraft-like testbed for general-purpose embodied agent research. CrafterDojo addresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for behavior priors, vision-language grounding, and instruction following, respectively. In addition, we provide toolkits for generating behavior and caption datasets (CrafterPlay and CrafterCaption), reference agent implementations, benchmark evaluations, and a complete open-source codebase.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Junyeong Park, Hyeonseo Cho, Sungjin Ahn</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13579v1</id>
    <title>Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance</title>
    <updated>2025-08-20T04:00:19.908335+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13579" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13579v1 Announce Type: new 
Abstract: Improving large language models (LLMs) for electronic health record (EHR) reasoning is essential for enabling accurate and generalizable clinical predictions. While LLMs excel at medical text understanding, they underperform on EHR-based prediction tasks due to challenges in modeling temporally structured, high-dimensional data. Existing approaches often rely on hybrid paradigms, where LLMs serve merely as frozen prior retrievers while downstream deep learning (DL) models handle prediction, failing to improve the LLM's intrinsic reasoning capacity and inheriting the generalization limitations of DL models. To this end, we propose EAG-RL, a novel two-stage training framework designed to intrinsically enhance LLMs' EHR reasoning ability through expert attention guidance, where expert EHR models refer to task-specific DL models trained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise reasoning trajectories using expert-guided Monte Carlo Tree Search to effectively initialize the LLM's policy. Then, EAG-RL further optimizes the policy via reinforcement learning by aligning the LLM's attention with clinically salient features identified by expert EHR models. Extensive experiments on two real-world EHR datasets show that EAG-RL improves the intrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also enhancing robustness to feature perturbations and generalization to unseen clinical domains. These results demonstrate the practical potential of EAG-RL for real-world deployment in clinical prediction tasks. Our code have been available at https://github.com/devilran6/EAG-RL.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yue Fang, Yuxin Guo, Jiaran Gao, Hongxin Ding, Xinke Jiang, Weibin Liao, Yongxin Xu, Yinghao Zhu, Zhibang Yang, Liantao Ma, Junfeng Zhao, Yasha Wang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13587v1</id>
    <title>Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation</title>
    <updated>2025-08-20T04:00:19.908254+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13587" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13587v1 Announce Type: new 
Abstract: While reinforcement learning (RL) has proven highly effective for general reasoning in vision-language models, its application to tasks requiring in-depth understanding of information-rich images and generation of structured outputs remains underexplored. Chart-to-code generation exemplifies this challenge, demanding complex reasoning over visual charts to generate structured code. Supervised fine-tuning (SFT) alone is often insufficient, highlighting the need for effective RL strategies that appropriately reward structured outputs. We systematically investigate the performance plateau in SFT through large-scale experiments and propose Multimodal Structured Reinforcement Learning (MSRL) for chart-to-code generation, which substantially breaks through this plateau. We construct the largest training corpus to date, containing 3 million chart-code pairs from real-world arXiv tables to mitigate simplistic patterns of prior synthetic data. Despite reaching state-of-the-art performance, our experiments show that scaling SFT data eventually hits a plateau where further increases yield negligible improvements. Our MSRL method leverages a multi-granularity structured reward system using multimodal textual and visual feedback. At the textual level, rule-based rewards validate fine-grained code details. At the visual level, model-based rewards assess structural similarity by rendering generated code into images and employing an evaluator model. We implement this within a two-stage curriculum for training stability. Results demonstrate that MSRL significantly breaks the SFT plateau, improving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA benchmarks respectively, achieving competitive performance with advanced closed-source models.</summary>
    <category term="cs.AI"/>
    <category term="cs.CV"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Liming Zheng, Yufeng Zhong, Lin Ma</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13634v1</id>
    <title>V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task</title>
    <updated>2025-08-20T04:00:19.908176+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13634" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13634v1 Announce Type: new 
Abstract: Precise localization of GUI elements is crucial for the development of GUI agents. Traditional methods rely on bounding box or center-point regression, neglecting spatial interaction uncertainty and visual-semantic hierarchies. Recent methods incorporate attention mechanisms but still face two key issues: (1) ignoring processing background regions causes attention drift from the desired area, and (2) uniform labeling fails to distinguish between center and edges of the target UI element, leading to click imprecision. Inspired by how humans visually process and interact with GUI elements, we propose the Valley-to-Peak (V2P) method to address these issues. To mitigate background distractions, V2P introduces a suppression attention mechanism that minimizes the model's focus on irrelevant regions to highlight the intended region. For the issue of center-edge distinction, V2P applies a Fitts' Law-inspired approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight gradually decreases from the center towards the edges. The weight distribution follows a Gaussian function, with the variance determined by the target's size. Consequently, V2P effectively isolates the target area and teaches the model to concentrate on the most essential point of the UI element. The model trained by V2P achieves the performance with 92.3% and 50.5% on two benchmarks ScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's contribution, highlighting V2P's generalizability for precise GUI grounding tasks.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Jikai Chen, Long Chen, Dong Wang, Leilei Gan, Chenyi Zhuang, Jinjie Gu</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13663v1</id>
    <title>Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints</title>
    <updated>2025-08-20T04:00:19.908111+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13663" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13663v1 Announce Type: new 
Abstract: Methods for query answering over incomplete knowledge graphs retrieve entities that are likely to be answers, which is particularly useful when such answers cannot be reached by direct graph traversal due to missing edges. However, existing approaches have focused on queries formalized using first-order-logic. In practice, many real-world queries involve constraints that are inherently vague or context-dependent, such as preferences for attributes or related categories. Addressing this gap, we introduce the problem of query answering with soft constraints. We propose a Neural Query Reranker (NQR) designed to adjust query answer scores by incorporating soft constraints without disrupting the original answers to a query. NQR operates interactively, refining answers based on incremental examples of preferred and non-preferred entities. We extend existing QA benchmarks by generating datasets with soft constraints. Our experiments demonstrate that NQR can capture soft constraints while maintaining robust query answering performance.</summary>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Daniel Daza, Alberto Bernardi, Luca Costabello, Christophe Gueret, Masoud Mansoury, Michael Cochez, Martijn Schut</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13672v1</id>
    <title>ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings</title>
    <updated>2025-08-20T04:00:19.908023+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13672" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13672v1 Announce Type: new 
Abstract: Explainable Artificial Intelligence (XAI) methods, such as Local Interpretable Model-Agnostic Explanations (LIME), have advanced the interpretability of black-box machine learning models by approximating their behavior locally using interpretable surrogate models. However, LIME's inherent randomness in perturbation and sampling can lead to locality and instability issues, especially in scenarios with limited training data. In such cases, data scarcity can result in the generation of unrealistic variations and samples that deviate from the true data manifold. Consequently, the surrogate model may fail to accurately approximate the complex decision boundary of the original model. To address these challenges, we propose a novel Instance-based Transfer Learning LIME framework (ITL-LIME) that enhances explanation fidelity and stability in data-constrained environments. ITL-LIME introduces instance transfer learning into the LIME framework by leveraging relevant real instances from a related source domain to aid the explanation process in the target domain. Specifically, we employ clustering to partition the source domain into clusters with representative prototypes. Instead of generating random perturbations, our method retrieves pertinent real source instances from the source cluster whose prototype is most similar to the target instance. These are then combined with the target instance's neighboring real instances. To define a compact locality, we further construct a contrastive learning-based encoder as a weighting mechanism to assign weights to the instances from the combined set based on their proximity to the target instance. Finally, these weighted source and target instances are used to train the surrogate model for explanation purposes.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Rehan Raza, Guanjin Wang, Kevin Wong, Hamid Laga, Marco Fisichella</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13675v1</id>
    <title>Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks</title>
    <updated>2025-08-20T04:00:19.907938+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13675" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13675v1 Announce Type: new 
Abstract: Knowledge Graphs are used for various purposes, including business applications, biomedical analyses, or digital twins in industry 4.0. In this paper, we investigate knowledge graphs describing household actions, which are beneficial for controlling household robots and analyzing video footage. In the latter case, the information extracted from videos is notoriously incomplete, and completing the knowledge graph for enhancing the situational picture is essential. In this paper, we show that, while a standard link prediction problem, situational knowledge graphs have special characteristics that render many link prediction algorithms not fit for the job, and unable to outperform even simple baselines.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Mariam Arustashvili, J\"org Deigm\"oller, Heiko Paulheim</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13676v1</id>
    <title>MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model</title>
    <updated>2025-08-20T04:00:19.902433+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13676" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13676v1 Announce Type: new 
Abstract: To maintain the company's talent pool, recruiters need to continuously search for resumes from third-party websites (e.g., LinkedIn, Indeed). However, fetched resumes are often incomplete and inaccurate. To improve the quality of third-party resumes and enrich the company's talent pool, it is essential to conduct duplication detection between the fetched resumes and those already in the company's talent pool. Such duplication detection is challenging due to the semantic complexity, structural heterogeneity, and information incompleteness of resume texts. To this end, we propose MHSNet, an multi-level identity verification framework that fine-tunes BGE-M3 using contrastive learning. With the fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and dense representations for resumes, enabling the computation of corresponding multi-level semantic similarities. Moreover, the state-aware Mixture-of-Experts (MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental results verify the effectiveness of MHSNet</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
    <dc:creator>Yu Li, Zulong Chen, Wenjian Xu, Hong Wen, Yipeng Yu, Man Lung Yiu, Yuyu Yin</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13678v1</id>
    <title>Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models</title>
    <updated>2025-08-20T04:00:19.902353+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13678" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13678v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown promising results across various tasks, yet their reasoning capabilities remain a fundamental challenge. Developing AI systems with strong reasoning capabilities is regarded as a crucial milestone in the pursuit of Artificial General Intelligence (AGI) and has garnered considerable attention from both academia and industry. Various techniques have been explored to enhance the reasoning capabilities of LLMs, with neuro-symbolic approaches being a particularly promising way. This paper comprehensively reviews recent developments in neuro-symbolic approaches for enhancing LLM reasoning. We first present a formalization of reasoning tasks and give a brief introduction to the neurosymbolic learning paradigm. Then, we discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs from three perspectives: Symbolic-&gt;LLM, LLM-&gt;Symbolic, and LLM+Symbolic. Finally, we discuss several key challenges and promising future directions. We have also released a GitHub repository including papers and resources related to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.</summary>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Xiao-Wen Yang, Jie-Jing Shao, Lan-Zhe Guo, Bo-Wen Zhang, Zhi Zhou, Lin-Han Jia, Wang-Zhou Dai, Yu-Feng Li</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13697v1</id>
    <title>The DeepLog Neurosymbolic Machine</title>
    <updated>2025-08-20T04:00:19.902300+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13697" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13697v1 Announce Type: new 
Abstract: We contribute a theoretical and operational framework for neurosymbolic AI called DeepLog. DeepLog introduces building blocks and primitives for neurosymbolic AI that make abstraction of commonly used representations and computational mechanisms used in neurosymbolic AI. DeepLog can represent and emulate a wide range of neurosymbolic systems. It consists of two key components. The first is the DeepLog language for specifying neurosymbolic models and inference tasks. This language consists of an annotated neural extension of grounded first-order logic, and makes abstraction of the type of logic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the architecture or in the loss function. The second DeepLog component is situated at the computational level and uses extended algebraic circuits as computational graphs. Together these two components are to be considered as a neurosymbolic abstract machine, with the DeepLog language as the intermediate level of abstraction and the circuits level as the computational one. DeepLog is implemented in software, relies on the latest insights in implementing algebraic circuits on GPUs, and is declarative in that it is easy to obtain different neurosymbolic models by making different choices for the underlying algebraic structures and logics. The generality and efficiency of the DeepLog neurosymbolic machine is demonstrated through an experimental comparison between 1) different fuzzy and probabilistic logics, 2) between using logic in the architecture or in the loss function, and 3) between a standalone CPU-based implementation of a neurosymbolic AI system and a DeepLog GPU-based one.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Vincent Derkinderen, Robin Manhaeve, Rik Adriaensen, Lucas Van Praet, Lennert De Smet, Giuseppe Marra, Luc De Raedt</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13721v1</id>
    <title>CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning</title>
    <updated>2025-08-20T04:00:19.902247+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13721" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13721v1 Announce Type: new 
Abstract: Large language model (LLM) agents-especially smaller, open-source models-often produce causally invalid or incoherent actions in collaborative tasks due to their reliance on surface-level correlations rather than grounded causal reasoning. This limitation undermines their performance in terms of coordination and planning in dynamic environments. We address this challenge with CausalPlan, a two-phase framework that integrates explicit structural causal reasoning into the LLM planning process. At the core of CausalPlan is the Structural Causal Action (SCA) model, which learns a causal graph from agent trajectories to capture how prior actions and current environment states influence future decisions. This structure is then used to guide action selection by assigning causal scores to LLM-generated proposals, reweighting them accordingly, or falling back to causally grounded alternatives when needed. By embedding this causal knowledge directly into the decision loop, CausalPlan constrains planning to intervention-consistent behaviours without requiring fine-tuning of the LLM itself. We evaluate CausalPlan on the Overcooked-AI benchmark across five multi-agent coordination tasks and four LLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B. Experimental results show that CausalPlan consistently reduces invalid actions and improves collaboration in both AI-AI and human-AI settings, outperforming strong reinforcement learning baselines. Our findings highlight the value of causality-driven planning for deploying efficient, interpretable, and generalisable multi-agent LLM systems.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Minh Hoang Nguyen, Van Dai Do, Dung Nguyen, Thin Nguyen, Hung Le</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13754v1</id>
    <title>Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making</title>
    <updated>2025-08-20T04:00:19.902194+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13754" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13754v1 Announce Type: new 
Abstract: Medical Decision-Making (MDM) is a complex process requiring substantial domain-specific expertise to effectively synthesize heterogeneous and complicated clinical information. While recent advancements in Large Language Models (LLMs) show promise in supporting MDM, single-LLM approaches are limited by their parametric knowledge constraints and static training corpora, failing to robustly integrate the clinical information. To address this challenge, we propose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC) framework to enhance the accuracy and reliability of MDM systems. It operates in two stages: (i) expertise-aware agent recruitment and (ii) confidence- and adversarial-driven multi-agent collaboration. Specifically, in the first stage, we use a publicly available corpus to construct an LLM expertise table for capturing expertise-specific strengths of multiple LLMs across medical department categories and query difficulty levels. This table enables the subsequent dynamic selection of the optimal LLMs to act as medical expert agents for each medical query during the inference phase. In the second stage, we employ selected agents to generate responses with self-assessed confidence scores, which are then integrated through the confidence fusion and adversarial validation to improve diagnostic reliability. We evaluate our EMRC framework on three public MDM datasets, where the results demonstrate that our EMRC outperforms state-of-the-art single- and multi-LLM methods, achieving superior diagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC achieves 74.45% accuracy, representing a 2.69% improvement over the best-performing closed-source model GPT- 4-0613, which demonstrates the effectiveness of our expertise-aware agent recruitment strategy and the agent complementarity in leveraging each LLM's specialized capabilities.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Liuxin Bao, Zhihao Peng, Xiaofei Zhou, Runmin Cong, Jiyong Zhang, Yixuan Yuan</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13811v1</id>
    <title>Quantifier Instantiations: To Mimic or To Revolt?</title>
    <updated>2025-08-20T04:00:19.902137+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13811" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13811v1 Announce Type: new 
Abstract: Quantified formulas pose a significant challenge for Satisfiability Modulo Theories (SMT) solvers due to their inherent undecidability. Existing instantiation techniques, such as e-matching, syntax-guided, model-based, conflict-based, and enumerative methods, often complement each other. This paper introduces a novel instantiation approach that dynamically learns from these techniques during solving. By treating observed instantiations as samples from a latent language, we use probabilistic context-free grammars to generate new, similar terms. Our method not only mimics successful past instantiations but also explores diversity by optionally inverting learned term probabilities, aiming to balance exploitation and exploration in quantifier reasoning.</summary>
    <category term="cs.AI"/>
    <category term="cs.LO"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Jan Jakub\r{u}v, Mikol\'a\v{s} Janota</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13828v1</id>
    <title>Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration</title>
    <updated>2025-08-20T04:00:19.902083+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13828" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13828v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) technology has been widely applied in recent years. However, despite the emergence of various RAG frameworks, a single RAG framework still cannot adapt well to a broad range of downstream tasks. Therefore, how to leverage the advantages of multiple RAG systems has become an area worth exploring. To address this issue, we have conducted a comprehensive and systematic investigation into ensemble methods based on RAG systems. Specifically, we have analyzed the RAG ensemble framework from both theoretical and mechanistic analysis perspectives. From the theoretical analysis, we provide the first explanation of the RAG ensemble framework from the perspective of information entropy. In terms of mechanism analysis, we have explored the RAG ensemble framework from both the pipeline and module levels. We carefully select four different pipelines (Branching, Iterative, Loop, and Agentic) and three different modules (Generator, Retriever, and Reranker) to solve seven different research questions. The experiments show that aggregating multiple RAG systems is both generalizable and robust, whether at the pipeline level or the module level. Our work lays the foundation for similar research on the multi-RAG system ensemble.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yifei Chen, Guanting Dong, Yutao Zhu, Zhicheng Dou</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13876v1</id>
    <title>Improved Generalized Planning with LLMs through Strategy Refinement and Reflection</title>
    <updated>2025-08-20T04:00:19.902020+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13876" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13876v1 Announce Type: new 
Abstract: LLMs have recently been used to generate Python programs representing generalized plans in PDDL planning, i.e., plans that generalize across the tasks of a given PDDL domain. Previous work proposed a framework consisting of three steps: the LLM first generates a summary and then a strategy for the domain, both in natural language, and then implements that strategy as a Python program, that gets debugged on example planning tasks. In that work, only one strategy is generated and passed directly to the program generation. If the strategy is incorrect, its implementation will therefore result in an incorrect generalized plan. Here, we introduce an approach that generates the strategy in the form of pseudocode and enables automatic debugging of the pseudocode, hence allowing us to identify and fix errors prior to the generation of the generalized plan itself. Additionally, we extend the Python debugging phase with a reflection step prompting the LLM to pinpoint the reason for the observed plan failure. Finally, we take inspiration from LLM code generation to produce several program variants and pick the best one. Running experiments on 17 benchmark domains, we show that these extensions substantially improve (and never deteriorate) the quality of the generalized plans. In 12 of the domains, our best Python programs solve all tasks that can be generated with the respective instance generator.</summary>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Katharina Stein, Nils Hodel, Daniel Fi\v{s}er, J\"org Hoffmann, Michael Katz, Alexander Koller</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13915v1</id>
    <title>Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback</title>
    <updated>2025-08-20T04:00:19.901967+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13915" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13915v1 Announce Type: new 
Abstract: Time-series data is central to decision-making in financial markets, yet building high-performing, interpretable, and auditable models remains a major challenge. While Automated Machine Learning (AutoML) frameworks streamline model development, they often lack adaptability and responsiveness to domain-specific needs and evolving objectives. Concurrently, Large Language Models (LLMs) have enabled agentic systems capable of reasoning, memory management, and dynamic code generation, offering a path toward more flexible workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular agentic framework designed to automate and enhance time-series modeling workflows for financial applications. The agent formalizes the pipeline as a structured, iterative decision process across three stages: model selection, code refinement, and fine-tuning, guided by contextual reasoning and experimental feedback. Central to our architecture is a planner agent equipped with structured knowledge banks, curated libraries of models and refinement strategies, which guide exploration, while improving interpretability and reducing error propagation. \textsf{TS-Agent} supports adaptive learning, robust debugging, and transparent auditing, key requirements for high-stakes environments such as financial services. Empirical evaluations on diverse financial forecasting and synthetic data generation tasks demonstrate that \textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic baselines, achieving superior accuracy, robustness, and decision traceability.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yihao Ang, Yifan Bao, Lei Jiang, Jiajie Tao, Anthony K. H. Tung, Lukasz Szpruch, Hao Ni</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13942v1</id>
    <title>The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management</title>
    <updated>2025-08-20T04:00:19.901914+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13942" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13942v1 Announce Type: new 
Abstract: The rise of autonomous, AI-driven agents in economic settings raises critical questions about their emergent strategic behavior. This paper investigates these dynamics in the cooperative context of a multi-echelon supply chain, a system famously prone to instabilities like the bullwhip effect. We conduct computational experiments with generative AI agents, powered by Large Language Models (LLMs), within a controlled supply chain simulation designed to isolate their behavioral tendencies. Our central finding is the "collaboration paradox": a novel, catastrophic failure mode where theoretically superior collaborative AI agents, designed with Vendor-Managed Inventory (VMI) principles, perform even worse than non-AI baselines. We demonstrate that this paradox arises from an operational flaw where agents hoard inventory, starving the system. We then show that resilience is only achieved through a synthesis of two distinct layers: high-level, AI-driven proactive policy-setting to establish robust operational targets, and a low-level, collaborative execution protocol with proactive downstream replenishment to maintain stability. Our final framework, which implements this synthesis, can autonomously generate, evaluate, and quantify a portfolio of viable strategic choices. The work provides a crucial insight into the emergent behaviors of collaborative AI agents and offers a blueprint for designing stable, effective AI-driven systems for business analytics.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Soumyadeep Dhar</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13975v1</id>
    <title>ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation</title>
    <updated>2025-08-20T04:00:19.901861+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13975" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13975v1 Announce Type: new 
Abstract: This contribution is concerned with the following issue: can pretrained large language models (LLMs) be refined and customized to the point where they become virtual assistants helping experts with the effective use of a simulation tool? In this case study, the ``simulation tool'' considered is PyChrono, an open source multi-physics dynamics engine for multibody systems. We present a framework for refining and customizing both open- and closed-source LLMs to harness the power of AI in generating scripts that perform PyChrono virtual experiments. We refine and customize several classes of LLMs through a process that leads to a quantifiable improvement in the quality of the generated PyChrono simulation scripts. These scripts can range from simple single-pendulum simulations to complex virtual experiments involving full vehicles on deformable terrain. While the generated scripts are rarely perfect, they often serve as strong starting points for the user to modify and improve on. Additionally, the LLM can answer specific API questions about the simulator, or recommend modeling approaches. The framework discussed is general and can be applied to lower the entry barrier for simulation tools associated with other application domains.</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Jingquan Wang, Andrew Negrut, Harry Zhang, Khailanii Slaton, Shu Wang, Radu Serban, Jinlong Wu, Dan Negrut</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.14020v1</id>
    <title>A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem</title>
    <updated>2025-08-20T04:00:19.901801+00:00</updated>
    <link href="https://arxiv.org/abs/2508.14020" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.14020v1 Announce Type: new 
Abstract: The longest run subsequence (LRS) problem is an NP-hard combinatorial optimization problem belonging to the class of subsequence problems from bioinformatics. In particular, the problem plays a role in genome reassembly. In this paper, we present a solution to the LRS problem using a Biased Random Key Genetic Algorithm (BRKGA). Our approach places particular focus on the computational efficiency of evaluating individuals, which involves converting vectors of gray values into valid solutions to the problem. For comparison purposes, a Max-Min Ant System is developed and implemented. This is in addition to the application of the integer linear programming solver CPLEX for solving all considered problem instances. The computation results show that the proposed BRKGA is currently a state-of-the-art technique for the LRS problem. Nevertheless, the results also show that there is room for improvement, especially in the context of input strings based on large alphabet sizes.</summary>
    <category term="cs.AI"/>
    <category term="cs.DM"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Christian Blum, Pedro Pinacho-Davidson</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.14040v1</id>
    <title>ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents</title>
    <updated>2025-08-20T04:00:19.901748+00:00</updated>
    <link href="https://arxiv.org/abs/2508.14040" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.14040v1 Announce Type: new 
Abstract: We introduce ComputerRL, a framework for autonomous desktop intelligence that enables agents to operate complex digital workspaces skillfully. ComputerRL features the API-GUI paradigm, which unifies programmatic API calls and direct GUI interaction to address the inherent mismatch between machine agents and human-centric desktop environments. Scaling end-to-end RL training is crucial for improvement and generalization across diverse desktop tasks, yet remains challenging due to environmental inefficiency and instability in extended training. To support scalable and robust training, we develop a distributed RL infrastructure capable of orchestrating thousands of parallel virtual desktop environments to accelerate large-scale online RL. Furthermore, we propose Entropulse, a training strategy that alternates reinforcement learning with supervised fine-tuning, effectively mitigating entropy collapse during extended training runs. We employ ComputerRL on open models GLM-4-9B-0414 and Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%, demonstrating significant improvements for general agents in desktop automation. The algorithm and framework are adopted in building AutoGLM (Liu et al., 2024a)</summary>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>new</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Hanyu Lai, Xiao Liu, Yanxiao Zhao, Han Xu, Hanchen Zhang, Bohao Jing, Yanyu Ren, Shuntian Yao, Yuxiao Dong, Jie Tang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.00875v1</id>
    <title>Preliminary suggestions for rigorous GPAI model evaluations</title>
    <updated>2025-08-20T04:00:19.901691+00:00</updated>
    <link href="https://arxiv.org/abs/2508.00875" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.00875v1 Announce Type: cross 
Abstract: This document presents a preliminary compilation of general-purpose AI (GPAI) evaluation practices that may promote internal validity, external validity and reproducibility. It includes suggestions for human uplift studies and benchmark evaluations, as well as cross-cutting suggestions that may apply to many different evaluation types. Suggestions are organised across four stages in the evaluation life cycle: design, implementation, execution and documentation. Drawing from established practices in machine learning, statistics, psychology, economics, biology and other fields recognised to have important lessons for AI evaluation, these suggestions seek to contribute to the conversation on the nascent and evolving field of the science of GPAI evaluations. The intended audience of this document includes providers of GPAI models presenting systemic risk (GPAISR), for whom the EU AI Act lays out specific evaluation requirements; third-party evaluators; policymakers assessing the rigour of evaluations; and academic researchers developing or conducting GPAI evaluations.</summary>
    <category term="cs.CY"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <arxiv:DOI>10.7249/PEA3971-1</arxiv:DOI>
    <dc:creator>Patricia Paskov, Michael J. Byun, Kevin Wei, Toby Webster</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.12365v1</id>
    <title>TaoSR1: The Thinking Model for E-commerce Relevance Search</title>
    <updated>2025-08-20T04:00:19.901625+00:00</updated>
    <link href="https://arxiv.org/abs/2508.12365" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.12365v1 Announce Type: cross 
Abstract: Query-product relevance prediction is a core task in e-commerce search. BERT-based models excel at semantic matching but lack complex reasoning capabilities. While Large Language Models (LLMs) are explored, most still use discriminative fine-tuning or distill to smaller models for deployment. We propose a framework to directly deploy LLMs for this task, addressing key challenges: Chain-of-Thought (CoT) error accumulation, discriminative hallucination, and deployment feasibility. Our framework, TaoSR1, involves three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning; (2) Offline sampling with a pass@N strategy and Direct Preference Optimization (DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO) to mitigate discriminative hallucination. Additionally, post-CoT processing and a cumulative probability-based partitioning method enable efficient online deployment. TaoSR1 significantly outperforms baselines on offline datasets and achieves substantial gains in online side-by-side human evaluations, introducing a novel paradigm for applying CoT reasoning to relevance classification.</summary>
    <category term="cs.IR"/>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Chenhe Dong, Shaowei Yao, Pengkun Jiao, Jianhui Yang, Yiming Jin, Zerui Huang, Xiaojiang Zhou, Dan Ou, Haihong Tang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.12448v1</id>
    <title>Uncovering Emergent Physics Representations Learned In-Context by Large Language Models</title>
    <updated>2025-08-20T04:00:19.901570+00:00</updated>
    <link href="https://arxiv.org/abs/2508.12448" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.12448v1 Announce Type: cross 
Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL) abilities, enabling them to solve wide range of tasks via textual prompts alone. As these capabilities advance, the range of applicable domains continues to expand significantly. However, identifying the precise mechanisms or internal structures within LLMs that allow successful ICL across diverse, distinct classes of tasks remains elusive. Physics-based tasks offer a promising testbed for probing this challenge. Unlike synthetic sequences such as basic arithmetic or symbolic equations, physical systems provide experimentally controllable, real-world data based on structured dynamics grounded in fundamental principles. This makes them particularly suitable for studying the emergent reasoning behaviors of LLMs in a realistic yet tractable setting. Here, we mechanistically investigate the ICL ability of LLMs, especially focusing on their ability to reason about physics. Using a dynamics forecasting task in physical systems as a proxy, we evaluate whether LLMs can learn physics in context. We first show that the performance of dynamics forecasting in context improves with longer input contexts. To uncover how such capability emerges in LLMs, we analyze the model's residual stream activations using sparse autoencoders (SAEs). Our experiments reveal that the features captured by SAEs correlate with key physical variables, such as energy. These findings demonstrate that meaningful physical concepts are encoded within LLMs during in-context learning. In sum, our work provides a novel case study that broadens our understanding of how LLMs learn in context.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yeongwoo Song, Jaeyong Bae, Dong-Kyum Kim, Hawoong Jeong</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13156v1</id>
    <title>EvoVerilog: Large Langugage Model Assisted Evolution of Verilog Code</title>
    <updated>2025-08-20T04:00:19.901515+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13156" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13156v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated great potential in automating the generation of Verilog hardware description language code for hardware design. This automation is critical to reducing human effort in the complex and error-prone process of hardware design.
  However, existing approaches predominantly rely on human intervention and fine-tuning using curated datasets, limiting their scalability in automated design workflows.
  Although recent iterative search techniques have emerged, they often fail to explore diverse design solutions and may underperform simpler approaches such as repeated prompting.
  To address these limitations, we introduce EvoVerilog, a novel framework that combines the reasoning capabilities of LLMs with evolutionary algorithms to automatically generate and refine Verilog code.
  EvoVerilog utilizes a multiobjective, population-based search strategy to explore a wide range of design possibilities without requiring human intervention.
  Extensive experiments demonstrate that EvoVerilog achieves state-of-the-art performance, with pass@10 scores of 89.1 and 80.2 on the VerilogEval-Machine and VerilogEval-Human benchmarks, respectively. Furthermore, the framework showcases its ability to explore diverse designs by simultaneously generating a variety of functional Verilog code while optimizing resource utilization.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Ping Guo, Yiting Wang, Wanghao Ye, Yexiao He, Ziyao Wang, Xiaopeng Dai, Ang Li, Qingfu Zhang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13157v1</id>
    <title>Image2Net: Datasets, Benchmark and Hybrid Framework to Convert Analog Circuit Diagrams into Netlists</title>
    <updated>2025-08-20T04:00:19.901456+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13157" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13157v1 Announce Type: cross 
Abstract: Large Language Model (LLM) exhibits great potential in designing of analog integrated circuits (IC) because of its excellence in abstraction and generalization for knowledge. However, further development of LLM-based analog ICs heavily relies on textual description of analog ICs, while existing analog ICs are mostly illustrated in image-based circuit diagrams rather than text-based netlists. Converting circuit diagrams to netlists help LLMs to enrich the knowledge of analog IC. Nevertheless, previously proposed conversion frameworks face challenges in further application because of limited support of image styles and circuit elements. Up to now, it still remains a challenging task to effectively convert complex circuit diagrams into netlists. To this end, this paper constructs and opensources a new dataset with rich styles of circuit diagrams as well as balanced distribution of simple and complex analog ICs. And a hybrid framework, named Image2Net, is proposed for practical conversion from circuit diagrams to netlists. The netlist edit distance (NED) is also introduced to precisely assess the difference between the converted netlists and ground truth. Based on our benchmark, Image2Net achieves 80.77\% successful rate, which is 34.62\%-45.19\% higher than previous works. Specifically, the proposed work shows 0.116 averaged NED, which is 62.1\%-69.6\% lower than state-of-the-arts.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <category term="cs.CV"/>
    <category term="eess.IV"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
    <dc:creator>Haohang Xu, Chengjie Liu, Qihang Wang, Wenhao Huang, Yongjian Xu, Weiyu Chen, Anlan Peng, Zhijun Li, Bo Li, Lei Qi, Jun Yang, Yuan Du, Li Du</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13161v1</id>
    <title>Piano: A Multi-Constraint Pin Assignment-Aware Floorplanner</title>
    <updated>2025-08-20T04:00:19.901398+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13161" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13161v1 Announce Type: cross 
Abstract: Floorplanning is a critical step in VLSI physical design, increasingly complicated by modern constraints such as fixed-outline requirements, whitespace removal, and the presence of pre-placed modules. In addition, the assignment of pins on module boundaries significantly impacts the performance of subsequent stages, including detailed placement and routing. However, traditional floorplanners often overlook pin assignment with modern constraints during the floorplanning stage. In this work, we introduce Piano, a floorplanning framework that simultaneously optimizes module placement and pin assignment under multiple constraints. Specifically, we construct a graph based on the geometric relationships among modules and their netlist connections, then iteratively search for shortest paths to determine pin assignments. This graph-based method also enables accurate evaluation of feedthrough and unplaced pins, thereby guiding overall layout quality. To further improve the design, we adopt a whitespace removal strategy and employ three local optimizers to enhance layout metrics under multi-constraint scenarios. Experimental results on widely used benchmark circuits demonstrate that Piano achieves an average 6.81% reduction in HPWL, a 13.39% decrease in feedthrough wirelength, a 16.36% reduction in the number of feedthrough modules, and a 21.21% drop in unplaced pins, while maintaining zero whitespace.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <dc:creator>Zhexuan Xu, Kexin Zhou, Jie Wang, Zijie Geng, Siyuan Xu, Shixiong Kai, Mingxuan Yuan, Feng Wu</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13163v1</id>
    <title>Sustainable AI Training via Hardware-Software Co-Design on NVIDIA, AMD, and Emerging GPU Architectures</title>
    <updated>2025-08-20T04:00:19.901340+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13163" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13163v1 Announce Type: cross 
Abstract: In particular, large-scale deep learning and artificial intelligence model training uses a lot of computational power and energy, so it poses serious sustainability issues. The fast rise in model complexity has resulted in exponential increases in energy consumption, increasing the demand for techniques maximizing computational efficiency and lowering environmental impact. This work explores environmentally driven performance optimization methods especially intended for advanced GPU architectures from NVIDIA, AMD, and other emerging GPU architectures. Our main focus is on investigating hardware-software co-design techniques meant to significantly increase memory-level and kernel-level operations, so improving performance-per-watt measures. Our thorough research encompasses evaluations of specialized tensor and matrix cores, advanced memory optimization methods, and creative integration approaches that taken together result in notable energy efficiency increases. We also discuss important software-level optimizations that augment hardware capability including mixed-precision arithmetic, advanced energy-aware scheduling algorithms, and compiler-driven kernel enhancements. Moreover, we methodically point out important research gaps and suggest future directions necessary to create really sustainable artificial intelligence systems. This paper emphasizes how major increases in training efficiency can be obtained by co-design of hardware and software, so lowering the environmental impact of artificial intelligence without compromising performance. To back up our analysis, we use real-world case studies from top companies like Meta, Google, Amazon, and others that show how these sustainable AI training methods are used in the real world.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <category term="cs.DC"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yashasvi Makin, Rahul Maliakkal</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13172v1</id>
    <title>White-Box Reasoning: Synergizing LLM Strategy and gm/Id Data for Automated Analog Circuit Design</title>
    <updated>2025-08-20T04:00:19.901278+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13172" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13172v1 Announce Type: cross 
Abstract: Analog IC design is a bottleneck due to its reliance on experience and inefficient simulations, as traditional formulas fail in advanced nodes. Applying Large Language Models (LLMs) directly to this problem risks mere "guessing" without engineering principles. We present a "synergistic reasoning" framework that integrates an LLM's strategic reasoning with the physical precision of the gm/Id methodology. By empowering the LLM with gm/Id lookup tables, it becomes a quantitative, data-driven design partner.
  We validated this on a two-stage op-amp, where our framework enabled the Gemini model to meet all TT corner specs in 5 iterations and extended optimization to all PVT corners. A crucial ablation study proved gm/Id data is key for this efficiency and precision; without it, the LLM is slower and deviates. Compared to a senior engineer's design, our framework achieves quasi-expert quality with an order-of-magnitude improvement in efficiency. This work validates a path for true analog design automation by combining LLM reasoning with scientific circuit design methodologies.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Jianqiu Chen, Siqi Li, Xu He</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13179v1</id>
    <title>Toward an African Agenda for AI Safety</title>
    <updated>2025-08-20T04:00:19.901218+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13179" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13179v1 Announce Type: cross 
Abstract: This paper maps Africa's distinctive AI risk profile, from deepfake fuelled electoral interference and data colonial dependency to compute scarcity, labour disruption and disproportionate exposure to climate driven environmental costs. While major benefits are promised to accrue, the availability, development and adoption of AI also mean that African people and countries face particular AI safety risks, from large scale labour market disruptions to the nefarious use of AI to manipulate public opinion. To date, African perspectives have not been meaningfully integrated into global debates and processes regarding AI safety, leaving African stakeholders with limited influence over the emerging global AI safety governance agenda. While there are Computer Incident Response Teams on the continent, none hosts a dedicated AI Safety Institute or office. We propose a five-point action plan centred on (i) a policy approach that foregrounds the protection of the human rights of those most vulnerable to experiencing the harmful socio-economic effects of AI; (ii) the establishment of an African AI Safety Institute; (iii) promote public AI literacy and awareness; (iv) development of early warning system with inclusive benchmark suites for 25+ African languages; and (v) an annual AU-level AI Safety &amp; Security Forum.</summary>
    <category term="cs.CY"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Samuel T. Segun, Rachel Adams, Ana Florido, Scott Timcke, Jonathan Shock, Leah Junck, Fola Adeleke, Nicolas Grossman, Ayantola Alayande, Jerry John Kponyo, Matthew Smith, Dickson Marfo Fosu, Prince Dawson Tetteh, Juliet Arthur, Stephanie Kasaon, Odilile Ayodele, Laetitia Badolo, Paul Plantinga, Michael Gastrow, Sumaya Nur Adan, Joanna Wiaterek, Cecil Abungu, Kojo Apeagyei, Luise Eder, Tegawende Bissyande</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13182v1</id>
    <title>Using Artificial Intuition in Distinct, Minimalist Classification of Scientific Abstracts for Management of Technology Portfolios</title>
    <updated>2025-08-20T04:00:19.901160+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13182" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13182v1 Announce Type: cross 
Abstract: Classification of scientific abstracts is useful for strategic activities but challenging to automate because the sparse text provides few contextual clues. Metadata associated with the scientific publication can be used to improve performance but still often requires a semi-supervised setting. Moreover, such schemes may generate labels that lack distinction -- namely, they overlap and thus do not uniquely define the abstract. In contrast, experts label and sort these texts with ease. Here we describe an application of a process we call artificial intuition to replicate the expert's approach, using a Large Language Model (LLM) to generate metadata. We use publicly available abstracts from the United States National Science Foundation to create a set of labels, and then we test this on a set of abstracts from the Chinese National Natural Science Foundation to examine funding trends. We demonstrate the feasibility of this method for research portfolio management, technology scouting, and other strategic activities.</summary>
    <category term="cs.DL"/>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
    <dc:creator>Prateek Ranka, Fred Morstatter, Andrea Belz, Alexandra Graddy-Reed</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13186v1</id>
    <title>MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents</title>
    <updated>2025-08-20T04:00:19.901104+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13186" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13186v1 Announce Type: cross 
Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated impressive performance in web browsing for deep search. While existing benchmarks such as BrowseComp evaluate these browsing abilities, they primarily focus on textual information, overlooking the prevalence of multimodal content. To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising 224 challenging, hand-crafted questions specifically designed to assess agents' multimodal retrieval and reasoning capabilities. These questions often incorporate images in prompts, and crucial information encountered during the search and reasoning process may also be embedded within images or videos on webpages. Consequently, methods relying solely on text prove insufficient for our benchmark. Additionally, we provide a verified checklist for each question, enabling fine-grained analysis of multimodal dependencies and reasoning paths. Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp reveals that even top models like OpenAI o3 with tools achieve only 29.02\% accuracy, highlighting the suboptimal multimodal capabilities and lack of native multimodal reasoning in current models.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <category term="cs.CV"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Shilong Li, Xingyuan Bu, Wenjie Wang, Jiaheng Liu, Jun Dong, Haoyang He, Hao Lu, Haozhe Zhang, Chenchen Jing, Zhen Li, Chuanhao Li, Jiayi Tian, Chenchen Zhang, Tianhao Peng, Yancheng He, Jihao Gu, Yuanxing Zhang, Jian Yang, Ge Zhang, Wenhao Huang, Wangchunshu Zhou, Zhaoxiang Zhang, Ruizhe Ding, Shilei Wen</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13187v1</id>
    <title>Combating Homelessness Stigma with LLMs: A New Multi-Modal Dataset for Bias Detection</title>
    <updated>2025-08-20T04:00:19.901047+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13187" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13187v1 Announce Type: cross 
Abstract: Homelessness is a persistent social challenge, impacting millions worldwide. Over 770,000 people experienced homelessness in the U.S. in 2024. Social stigmatization is a significant barrier to alleviation, shifting public perception, and influencing policymaking. Given that online and city council discourse reflect and influence part of public opinion, it provides valuable insights to identify and track social biases. This research contributes to alleviating homelessness by acting on public opinion. It introduces novel methods, building on natural language processing (NLP) and large language models (LLMs), to identify and measure PEH social bias expressed in digital spaces. We present a new, manually-annotated multi-modal dataset compiled from Reddit, X (formerly Twitter), news articles, and city council meeting minutes across 10 U.S. cities. This unique dataset provides evidence of the typologies of homelessness bias described in the literature. In order to scale up and automate the detection of homelessness bias online, we evaluate LLMs as classifiers. We applied both zero-shot and few-shot classification techniques to this data. We utilized local LLMs (Llama 3.2 3B Instruct, Qwen 2.5 7B Instruct, and Phi4 Instruct Mini) as well as closed-source API models (GPT-4.1, Gemini 2.5 Pro, and Grok-4). Our findings reveal that although there are significant inconsistencies in local LLM zero-shot classification, the in-context learning classification scores of local LLMs approach the classification scores of closed-source LLMs. Furthermore, LLMs outperform BERT when averaging across all categories. This work aims to raise awareness about the pervasive bias against PEH, develop new indicators to inform policy, and ultimately enhance the fairness and ethical application of Generative AI technologies.</summary>
    <category term="cs.CY"/>
    <category term="cs.AI"/>
    <category term="cs.CL"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Jonathan A. Karr Jr., Benjamin F. Herbst, Ting Hua, Matthew Hauenstein, Georgina Curto, Nitesh V. Chawla</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13189v1</id>
    <title>Preference Models assume Proportional Hazards of Utilities</title>
    <updated>2025-08-20T04:00:19.900981+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13189" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13189v1 Announce Type: cross 
Abstract: Approaches for estimating preferences from human annotated data typically involves inducing a distribution over a ranked list of choices such as the Plackett-Luce model. Indeed, modern AI alignment tools such as Reward Modelling and Direct Preference Optimization are based on the statistical assumptions posed by the Plackett-Luce model. In this paper, I will connect the Plackett-Luce model to another classical and well known statistical model, the Cox Proportional Hazards model and attempt to shed some light on the implications of the connection therein.</summary>
    <category term="stat.ML"/>
    <category term="cs.AI"/>
    <category term="cs.LG"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Chirag Nagpal</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13196v1</id>
    <title>Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis</title>
    <updated>2025-08-20T04:00:19.900924+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13196" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13196v1 Announce Type: cross 
Abstract: This paper introduces a novel approach for multimodal sentiment analysis on social media, particularly in the context of natural disasters, where understanding public sentiment is crucial for effective crisis management. Unlike conventional methods that process text and image modalities separately, our approach seamlessly integrates Convolutional Neural Network (CNN) based image analysis with Large Language Model (LLM) based text processing, leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to extract sentiment relevant features from the CrisisMMD dataset. To effectively model intermodal relationships, we introduce a contextual attention mechanism within the fusion process. Leveraging contextual-attention layers, this mechanism effectively captures intermodality interactions, enhancing the model's comprehension of complex relationships between textual and visual data. The deep neural network architecture of our model learns from these fused features, leading to improved accuracy compared to existing baselines. Experimental results demonstrate significant advancements in classifying social media data into informative and noninformative categories across various natural disasters. Our model achieves a notable 2.43% increase in accuracy and 5.18% in F1-score, highlighting its efficacy in processing complex multimodal data. Beyond quantitative metrics, our approach provides deeper insight into the sentiments expressed during crises. The practical implications extend to real time disaster management, where enhanced sentiment analysis can optimize the accuracy of emergency interventions. By bridging the gap between multimodal analysis, LLM powered text understanding, and disaster response, our work presents a promising direction for Artificial Intelligence (AI) driven crisis management solutions. Keywords:</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <category term="cs.IR"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Meriem Zerkouk, Miloud Mihoubi, Belkacem Chikhaoui</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13197v1</id>
    <title>The Rise of Generative AI for Metal-Organic Framework Design and Synthesis</title>
    <updated>2025-08-20T04:00:19.900871+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13197" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13197v1 Announce Type: cross 
Abstract: Advances in generative artificial intelligence are transforming how metal-organic frameworks (MOFs) are designed and discovered. This Perspective introduces the shift from laborious enumeration of MOF candidates to generative approaches that can autonomously propose and synthesize in the laboratory new porous reticular structures on demand. We outline the progress of employing deep learning models, such as variational autoencoders, diffusion models, and large language model-based agents, that are fueled by the growing amount of available data from the MOF community and suggest novel crystalline materials designs. These generative tools can be combined with high-throughput computational screening and even automated experiments to form accelerated, closed-loop discovery pipelines. The result is a new paradigm for reticular chemistry in which AI algorithms more efficiently direct the search for high-performance MOF materials for clean air and energy applications. Finally, we highlight remaining challenges such as synthetic feasibility, dataset diversity, and the need for further integration of domain knowledge.</summary>
    <category term="cond-mat.mtrl-sci"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Chenru Duan, Aditya Nandy, Shyam Chand Pal, Xin Yang, Wenhao Gao, Yuanqi Du, Hendrik Kra{\ss}, Yeonghun Kang, Varinia Bernales, Zuyang Ye, Tristan Pyle, Ray Yang, Zeqi Gu, Philippe Schwaller, Shengqian Ma, Shijing Sun, Al\'an Aspuru-Guzik, Seyed Mohamad Moosavi, Robert Wexler, Zhiling Zheng</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13201v1</id>
    <title>Benchmarking LLM-based Agents for Single-cell Omics Analysis</title>
    <updated>2025-08-20T04:00:19.900816+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13201" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13201v1 Announce Type: cross 
Abstract: The surge in multimodal single-cell omics data exposes limitations in traditional, manually defined analysis workflows. AI agents offer a paradigm shift, enabling adaptive planning, executable code generation, traceable decisions, and real-time knowledge fusion. However, the lack of a comprehensive benchmark critically hinders progress. We introduce a novel benchmarking evaluation system to rigorously assess agent capabilities in single-cell omics analysis. This system comprises: a unified platform compatible with diverse agent frameworks and LLMs; multidimensional metrics assessing cognitive program synthesis, collaboration, execution efficiency, bioinformatics knowledge integration, and task completion quality; and 50 diverse real-world single-cell omics analysis tasks spanning multi-omics, species, and sequencing technologies. Our evaluation reveals that Grok-3-beta achieves state-of-the-art performance among tested agent frameworks. Multi-agent frameworks significantly enhance collaboration and execution efficiency over single-agent approaches through specialized role division. Attribution analyses of agent capabilities identify that high-quality code generation is crucial for task success, and self-reflection has the most significant overall impact, followed by retrieval-augmented generation (RAG) and planning. This work highlights persistent challenges in code generation, long-context handling, and context-aware knowledge retrieval, providing a critical empirical foundation and best practices for developing robust AI agents in computational biology.</summary>
    <category term="q-bio.GN"/>
    <category term="cs.AI"/>
    <category term="cs.MA"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yang Liu, Lu Zhou, Ruikun He, Rongbo Shen, Yixue Li</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13207v1</id>
    <title>Utilizing the RAIN method and Graph SAGE Model to Identify Effective Drug Combinations for Gastric Neoplasm Treatment</title>
    <updated>2025-08-20T04:00:19.900762+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13207" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13207v1 Announce Type: cross 
Abstract: Background: Gastric neoplasm, primarily adenocarcinoma, is an aggressive cancer with high mortality, often diagnosed late, leading to complications like metastasis. Effective drug combinations are vital to address disease heterogeneity, enhance efficacy, reduce resistance, and improve patient outcomes. Methods: The RAIN method integrated Graph SAGE to propose drug combinations, using a graph model with p-value-weighted edges connecting drugs, genes, and proteins. NLP and systematic literature review (PubMed, Scopus, etc.) validated proposed drugs, followed by network meta-analysis to assess efficacy, implemented in Python. Results: Oxaliplatin, fluorouracil, and trastuzumab were identified as effective, supported by 61 studies. Fluorouracil alone had a p-value of 0.0229, improving to 0.0099 with trastuzumab, and 0.0069 for the triple combination, indicating superior efficacy. Conclusion: The RAIN method, combining AI and network meta-analysis, effectively identifies optimal drug combinations for gastric neoplasm, offering a promising strategy to enhance treatment outcomes and guide health policy.</summary>
    <category term="q-bio.QM"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>S. Z. Pirasteh, Ali A. Kiaei, Mahnaz Bush, Sabra Moghadam, Raha Aghaei, Behnaz Sadeghigol</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13209v1</id>
    <title>Research on Conversational Recommender System Considering Consumer Types</title>
    <updated>2025-08-20T04:00:19.900703+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13209" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13209v1 Announce Type: cross 
Abstract: Conversational Recommender Systems (CRS) provide personalized services through multi-turn interactions, yet most existing methods overlook users' heterogeneous decision-making styles and knowledge levels, which constrains both accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer Type-Enhanced Conversational Recommender System), a framework that integrates consumer type modeling into dialogue recommendation. Based on consumer type theory, we define four user categories--dependent, efficient, cautious, and expert--derived from two dimensions: decision-making style (maximizers vs. satisficers) and knowledge level (high vs. low). CT-CRS employs interaction histories and fine-tunes the large language model to automatically infer user types in real time, avoiding reliance on static questionnaires. We incorporate user types into state representation and design a type-adaptive policy that dynamically adjusts recommendation granularity, diversity, and attribute query complexity. To further optimize the dialogue policy, we adopt Inverse Reinforcement Learning (IRL), enabling the agent to approximate expert-like strategies conditioned on consumer type. Experiments on LastFM, Amazon-Book, and Yelp show that CTCRS improves recommendation success rate and reduces interaction turns compared to strong baselines. Ablation studies confirm that both consumer type modeling and IRL contribute significantly to performance gains. These results demonstrate that CT-CRS offers a scalable and interpretable solution for enhancing CRS personalization through the integration of psychological modeling and advanced policy optimization.</summary>
    <category term="cs.IR"/>
    <category term="cs.AI"/>
    <category term="cs.SI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yaying Luo, Hui Fang, Zhu Sun</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13214v1</id>
    <title>Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions</title>
    <updated>2025-08-20T04:00:19.900637+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13214" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13214v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have recently demonstrated strong emergent abilities in complex reasoning and zero-shot generalization, showing unprecedented potential for LLM-as-a-judge applications in education, peer review, and data quality evaluation. However, their robustness under prompt injection attacks, where malicious instructions are embedded into the content to manipulate outputs, remains a significant concern. In this work, we explore a frustratingly simple yet effective attack setting to test whether LLMs can be easily misled. Specifically, we evaluate LLMs on basic arithmetic questions (e.g., "What is 3 + 2?") presented as either multiple-choice or true-false judgment problems within PDF files, where hidden prompts are injected into the file. Our results reveal that LLMs are indeed vulnerable to such hidden prompt injection attacks, even in these trivial scenarios, highlighting serious robustness risks for LLM-as-a-judge applications.</summary>
    <category term="cs.CR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Xuyang Guo, Zekai Huang, Zhao Song, Jiahao Zhang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13219v1</id>
    <title>Deep Graph Neural Point Process For Learning Temporal Interactive Networks</title>
    <updated>2025-08-20T04:00:19.900577+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13219" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13219v1 Announce Type: cross 
Abstract: Learning temporal interaction networks(TIN) is previously regarded as a coarse-grained multi-sequence prediction problem, ignoring the network topology structure influence. This paper addresses this limitation and a Deep Graph Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node Aggregation Layer captures topological structures to generate static representation for users and items, while the Self Attentive Layer dynamically updates embeddings over time. By incorporating both dynamic and static embeddings into the event intensity function and optimizing the model via maximum likelihood estimation, DGNPP predicts events and occurrence time effectively. Experimental evaluations on three public datasets demonstrate that DGNPP achieves superior performance in event prediction and time prediction tasks with high efficiency, significantly outperforming baseline models and effectively mitigating the limitations of prior approaches.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Su Chen, Xiaohua Qi, Xixun Lin, Yanmin Shang, Xiaolin Xu, Yangxi Li</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13220v1</id>
    <title>MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols</title>
    <updated>2025-08-20T04:00:19.900522+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13220" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13220v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly integrated into real-world applications via the Model Context Protocol (MCP), a universal, open standard for connecting AI agents with data sources and external tools. While MCP enhances the capabilities of LLM-based agents, it also introduces new security risks and expands their attack surfaces. In this paper, we present the first systematic taxonomy of MCP security, identifying 17 attack types across 4 primary attack surfaces. We introduce MCPSecBench, a comprehensive security benchmark and playground that integrates prompt datasets, MCP servers, MCP clients, and attack scripts to evaluate these attacks across three major MCP providers. Our benchmark is modular and extensible, allowing researchers to incorporate custom implementations of clients, servers, and transport protocols for systematic security assessment. Experimental results show that over 85% of the identified attacks successfully compromise at least one platform, with core vulnerabilities universally affecting Claude, OpenAI, and Cursor, while prompt-based and tool-centric attacks exhibit considerable variability across different hosts and models. Overall, MCPSecBench standardizes the evaluation of MCP security and enables rigorous testing across all MCP layers.</summary>
    <category term="cs.CR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yixuan Yang, Daoyuan Wu, Yufan Chen</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13223v1</id>
    <title>MIRAGE: Towards AI-Generated Image Detection in the Wild</title>
    <updated>2025-08-20T04:00:19.900465+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13223" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13223v1 Announce Type: cross 
Abstract: The spreading of AI-generated images (AIGI), driven by advances in generative AI, poses a significant threat to information security and public trust. Existing AIGI detectors, while effective against images in clean laboratory settings, fail to generalize to in-the-wild scenarios. These real-world images are noisy, varying from ``obviously fake" images to realistic ones derived from multiple generative models and further edited for quality control. We address in-the-wild AIGI detection in this paper. We introduce Mirage, a challenging benchmark designed to emulate the complexity of in-the-wild AIGI. Mirage is constructed from two sources: (1) a large corpus of Internet-sourced AIGI verified by human experts, and (2) a synthesized dataset created through the collaboration between multiple expert generators, closely simulating the realistic AIGI in the wild. Building on this benchmark, we propose Mirage-R1, a vision-language model with heuristic-to-analytic reasoning, a reflective reasoning mechanism for AIGI detection. Mirage-R1 is trained in two stages: a supervised-fine-tuning cold start, followed by a reinforcement learning stage. By further adopting an inference-time adaptive thinking strategy, Mirage-R1 is able to provide either a quick judgment or a more robust and accurate conclusion, effectively balancing inference speed and performance. Extensive experiments show that our model leads state-of-the-art detectors by 5% and 10% on Mirage and the public benchmark, respectively. The benchmark and code will be made publicly available.</summary>
    <category term="cs.CV"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Cheng Xia, Manxi Lin, Jiexiang Tan, Xiaoxiong Du, Yang Qiu, Junjun Zheng, Xiangheng Kong, Yuning Jiang, Bo Zheng</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13228v1</id>
    <title>PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism</title>
    <updated>2025-08-20T04:00:19.900339+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13228" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13228v1 Announce Type: cross 
Abstract: This paper proposes PreSem-Surf, an optimized method based on the Neural Radiance Field (NeRF) framework, capable of reconstructing high-quality scene surfaces from RGB-D sequences in a short time. The method integrates RGB, depth, and semantic information to improve reconstruction performance. Specifically, a novel SG-MLP sampling structure combined with PR-MLP (Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering, allowing the model to capture scene-related information earlier and better distinguish noise from local details. Furthermore, progressive semantic modeling is adopted to extract semantic information at increasing levels of precision, reducing training time while enhancing scene understanding. Experiments on seven synthetic scenes with six evaluation metrics show that PreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while maintaining competitive results in NC, Accuracy, and Completeness, demonstrating its effectiveness and practical applicability.</summary>
    <category term="cs.GR"/>
    <category term="cs.AI"/>
    <category term="cs.CV"/>
    <category term="eess.IV"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yuyan Ye, Hang Xu, Yanghang Huang, Jiali Huang, Qian Weng</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13231v1</id>
    <title>Accelerating LLM Inference via Dynamic KV Cache Placement in Heterogeneous Memory System</title>
    <updated>2025-08-20T04:00:19.900283+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13231" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13231v1 Announce Type: cross 
Abstract: Large Language Model (LLM) inference is increasingly constrained by memory bandwidth, with frequent access to the key-value (KV) cache dominating data movement. While attention sparsity reduces some memory traffic, the relevance of past tokens varies over time, requiring the full KV cache to remain accessible and sustaining pressure on both bandwidth and capacity. With advances in interconnects such as NVLink and LPDDR5X, modern AI hardware now integrates high-bandwidth memory (HBM) with high-speed off-package DRAM, making heterogeneous memory systems a practical solution. This work investigates dynamic KV cache placement across such systems to maximize aggregated bandwidth utilization under capacity constraints. Rather than proposing a specific scheduling policy, we formulate the placement problem mathematically and derive a theoretical upper bound, revealing substantial headroom for runtime optimization. To our knowledge, this is the first formal treatment of dynamic KV cache scheduling in heterogeneous memory systems for LLM inference.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <category term="cs.PF"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Yunhua Fang, Rui Xie, Asad Ul Haq, Linsen Ma, Kaoutar El Maghraoui, Naigang Wang, Meng Wang, Liu Liu, Tong Zhang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13234v1</id>
    <title>The Role of AI in Facilitating Interdisciplinary Collaboration: Evidence from AlphaFold</title>
    <updated>2025-08-20T04:00:19.900227+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13234" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13234v1 Announce Type: cross 
Abstract: The acceleration of artificial intelligence (AI) in science is recognized and many scholars have begun to explore its role in interdisciplinary collaboration. However, the mechanisms and extent of this impact are still unclear. This study, using AlphaFold's impact on structural biologists, examines how AI technologies influence interdisciplinary collaborative patterns. By analyzing 1,247 AlphaFold-related papers and 7,700 authors from Scopus, we employ bibliometric analysis and causal inference to compare interdisciplinary collaboration between AlphaFold adopters and non-adopters. Contrary to the widespread belief that AI facilitates interdisciplinary collaboration, our findings show that AlphaFold increased structural biology-computer science collaborations by just 0.48%, with no measurable effect on other disciplines. Specifically, AI creates interdisciplinary collaboration demands with specific disciplines due to its technical characteristics, but this demand is weakened by technological democratization and other factors. These findings demonstrate that artificial intelligence (AI) alone has limited efficacy in bridging disciplinary divides or fostering meaningful interdisciplinary collaboration.</summary>
    <category term="cs.DL"/>
    <category term="cs.AI"/>
    <category term="cs.CY"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Naixuan Zhao, Chunli Wei, Xinyan Zhang, Jiang Li</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13236v1</id>
    <title>Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray</title>
    <updated>2025-08-20T04:00:19.900172+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13236" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13236v1 Announce Type: cross 
Abstract: Early detection and rapid intervention of lung cancer are crucial. Nonetheless, ensuring an accurate diagnosis is challenging, as physicians' ability to interpret chest X-rays varies significantly depending on their experience and degree of fatigue. Although medical AI has been rapidly advancing to assist in diagnosis, physicians' trust in such systems remains limited, preventing widespread clinical adoption. This skepticism fundamentally stems from concerns about its diagnostic uncertainty. In clinical diagnosis, physicians utilize extensive background knowledge and clinical experience. In contrast, medical AI primarily relies on repetitive learning of the target lesion to generate diagnoses based solely on that data. In other words, medical AI does not possess sufficient knowledge to render a diagnosis, leading to diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning Policy that can address the issue of knowledge deficiency by learning the physicians' background knowledge alongside the Chest X-ray lesion information. We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a 10% enhancement in sensitivity compared to the baseline model while also decreasing entropy as a measure of uncertainty by 0.2.</summary>
    <category term="cs.CV"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Hyeonjin Choi, Jinse Kim, Dong-yeon Yoo, Ju-sung Sun, Jung-won Lee</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13240v1</id>
    <title>Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis</title>
    <updated>2025-08-20T04:00:19.900119+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13240" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13240v1 Announce Type: cross 
Abstract: Understanding and quantifying human cognitive biases from empirical data has long posed a formidable challenge, particularly in cybersecurity, where defending against unknown adversaries is paramount. Traditional cyber defense strategies have largely focused on fortification, while some approaches attempt to anticipate attacker strategies by mapping them to cognitive vulnerabilities, yet they fall short in dynamically interpreting attacks in progress. In recognition of this gap, IARPA's ReSCIND program seeks to infer, defend against, and even exploit attacker cognitive traits. In this paper, we present a novel methodology that leverages large language models (LLMs) to extract quantifiable insights into the cognitive bias of loss aversion from hacker behavior. Our data are collected from an experiment in which hackers were recruited to attack a controlled demonstration network. We process the hacker generated notes using LLMs using it to segment the various actions and correlate the actions to predefined persistence mechanisms used by hackers. By correlating the implementation of these mechanisms with various operational triggers, our analysis provides new insights into how loss aversion manifests in hacker decision-making. The results demonstrate that LLMs can effectively dissect and interpret nuanced behavioral patterns, thereby offering a transformative approach to enhancing cyber defense strategies through real-time, behavior-based analysis.</summary>
    <category term="cs.CR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Soham Hans, Nikolos Gurney, Stacy Marsella, Sofia Hirschmann</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13246v1</id>
    <title>Involuntary Jailbreak</title>
    <updated>2025-08-20T04:00:19.900062+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13246" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13246v1 Announce Type: cross 
Abstract: In this study, we disclose a worrying new vulnerability in Large Language Models (LLMs), which we term \textbf{involuntary jailbreak}. Unlike existing jailbreak attacks, this weakness is distinct in that it does not involve a specific attack objective, such as generating instructions for \textit{building a bomb}. Prior attack methods predominantly target localized components of the LLM guardrail. In contrast, involuntary jailbreaks may potentially compromise the entire guardrail structure, which our method reveals to be surprisingly fragile. We merely employ a single universal prompt to achieve this goal. In particular, we instruct LLMs to generate several questions that would typically be rejected, along with their corresponding in-depth responses (rather than a refusal). Remarkably, this simple prompt strategy consistently jailbreaks the majority of leading LLMs, including Claude Opus 4.1, Grok 4, Gemini 2.5 Pro, and GPT 4.1. We hope this problem can motivate researchers and practitioners to re-evaluate the robustness of LLM guardrails and contribute to stronger safety alignment in future.</summary>
    <category term="cs.CR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yangyang Guo, Yangyan Li, Mohan Kankanhalli</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13247v1</id>
    <title>Goal-Directedness is in the Eye of the Beholder</title>
    <updated>2025-08-20T04:00:19.899995+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13247" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13247v1 Announce Type: cross 
Abstract: Our ability to predict the behavior of complex agents turns on the attribution of goals. Probing for goal-directed behavior comes in two flavors: Behavioral and mechanistic. The former proposes that goal-directedness can be estimated through behavioral observation, whereas the latter attempts to probe for goals in internal model states. We work through the assumptions behind both approaches, identifying technical and conceptual problems that arise from formalizing goals in agent systems. We arrive at the perhaps surprising position that goal-directedness cannot be measured objectively. We outline new directions for modeling goal-directedness as an emergent property of dynamic, multi-agent systems.</summary>
    <category term="cs.MA"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Nina Rajcic, Anders S{\o}gaard</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13257v1</id>
    <title>ViTAD: Timing Violation-Aware Debugging of RTL Code using Large Language Models</title>
    <updated>2025-08-20T04:00:19.899941+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13257" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13257v1 Announce Type: cross 
Abstract: In modern Very Large Scale Integrated (VLSI) circuit design flow, the Register-Transfer Level (RTL) stage presents a critical opportunity for timing optimization. Addressing timing violations at this early stage is essential, as modern systems demand higher speeds, where even minor timing violations can lead to functional failures or system crashes. However, traditional timing optimization heavily relies on manual expertise, requiring engineers to iteratively analyze timing reports and debug. To automate this process, this paper proposes ViTAD, a method that efficiently analyzes the root causes of timing violations and dynamically generates targeted repair strategies. Specifically, we first parse Verilog code and timing reports to construct a Signal Timing Dependency Graph (STDG). Based on the STDG, we perform violation path analysis and use large language models (LLMs) to infer the root causes of violations. Finally, by analyzing the causes of violations, we selectively retrieve relevant debugging knowledge from a domain-specific knowledge base to generate customized repair solutions. To evaluate the effectiveness of our method, we construct a timing violation dataset based on real-world open-source projects. This dataset contains 54 cases of violations. Experimental results show that our method achieves a 73.68% success rate in repairing timing violations, while the baseline using only LLM is 54.38%. Our method improves the success rate by 19.30%.</summary>
    <category term="cs.AR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Wenhao Lv, Yingjie Xia, Xiyuan Chen, Li Kuang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13288v1</id>
    <title>Hierarchical Conformal Classification</title>
    <updated>2025-08-20T04:00:19.899884+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13288" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13288v1 Announce Type: cross 
Abstract: Conformal prediction (CP) is a powerful framework for quantifying uncertainty in machine learning models, offering reliable predictions with finite-sample coverage guarantees. When applied to classification, CP produces a prediction set of possible labels that is guaranteed to contain the true label with high probability, regardless of the underlying classifier. However, standard CP treats classes as flat and unstructured, ignoring domain knowledge such as semantic relationships or hierarchical structure among class labels. This paper presents hierarchical conformal classification (HCC), an extension of CP that incorporates class hierarchies into both the structure and semantics of prediction sets. We formulate HCC as a constrained optimization problem whose solutions yield prediction sets composed of nodes at different levels of the hierarchy, while maintaining coverage guarantees. To address the combinatorial nature of the problem, we formally show that a much smaller, well-structured subset of candidate solutions suffices to ensure coverage while upholding optimality. An empirical evaluation on three new benchmarks consisting of audio, image, and text data highlights the advantages of our approach, and a user study shows that annotators significantly prefer hierarchical over flat prediction sets.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <category term="stat.ML"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
    <dc:creator>Floris den Hengst, In\`es Blin, Majid Mohammadi, Syed Ihtesham Hussain Shah, Taraneh Younesian</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13300v1</id>
    <title>GaitCrafter: Diffusion Model for Biometric Preserving Gait Synthesis</title>
    <updated>2025-08-20T04:00:19.899822+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13300" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13300v1 Announce Type: cross 
Abstract: Gait recognition is a valuable biometric task that enables the identification of individuals from a distance based on their walking patterns. However, it remains limited by the lack of large-scale labeled datasets and the difficulty of collecting diverse gait samples for each individual while preserving privacy. To address these challenges, we propose GaitCrafter, a diffusion-based framework for synthesizing realistic gait sequences in the silhouette domain. Unlike prior works that rely on simulated environments or alternative generative models, GaitCrafter trains a video diffusion model from scratch, exclusively on gait silhouette data. Our approach enables the generation of temporally consistent and identity-preserving gait sequences. Moreover, the generation process is controllable-allowing conditioning on various covariates such as clothing, carried objects, and view angle. We show that incorporating synthetic samples generated by GaitCrafter into the gait recognition pipeline leads to improved performance, especially under challenging conditions. Additionally, we introduce a mechanism to generate novel identities-synthetic individuals not present in the original dataset-by interpolating identity embeddings. These novel identities exhibit unique, consistent gait patterns and are useful for training models while maintaining privacy of real subjects. Overall, our work takes an important step toward leveraging diffusion models for high-quality, controllable, and privacy-aware gait data generation.</summary>
    <category term="cs.CV"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
    <dc:creator>Sirshapan Mitra, Yogesh S. Rawat</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13303v1</id>
    <title>Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters</title>
    <updated>2025-08-20T04:00:19.899761+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13303" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13303v1 Announce Type: cross 
Abstract: High-fidelity personalized human musculoskeletal models are crucial for simulating realistic behavior of physically coupled human-robot interactive systems and verifying their safety-critical applications in simulations before actual deployment, such as human-robot co-transportation and rehabilitation through robotic exoskeletons. Identifying subject-specific Hill-type muscle model parameters and bone dynamic parameters is essential for a personalized musculoskeletal model, but very challenging due to the difficulty of measuring the internal biomechanical variables in vivo directly, especially the joint torques. In this paper, we propose using Differentiable MusculoSkeletal Model (Diff-MSM) to simultaneously identify its muscle and bone parameters with an end-to-end automatic differentiation technique differentiating from the measurable muscle activation, through the joint torque, to the resulting observable motion without the need to measure the internal joint torques. Through extensive comparative simulations, the results manifested that our proposed method significantly outperformed the state-of-the-art baseline methods, especially in terms of accurate estimation of the muscle parameters (i.e., initial guess sampled from a normal distribution with the mean being the ground truth and the standard deviation being 10% of the ground truth could end up with an average of the percentage errors of the estimated values as low as 0.05%). In addition to human musculoskeletal modeling and simulation, the new parameter identification technique with the Diff-MSM has great potential to enable new applications in muscle health monitoring, rehabilitation, and sports science.</summary>
    <category term="cs.RO"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <arxiv:journal_reference>2025 IEEE/RSJ international conference on intelligent robots and systems (IROS)</arxiv:journal_reference>
    <dc:creator>Yingfan Zhou, Philip Sanderink, Sigurd Jager Lemming, Cheng Fang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13319v1</id>
    <title>A Surveillance Based Interactive Robot</title>
    <updated>2025-08-20T04:00:19.899703+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13319" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13319v1 Announce Type: cross 
Abstract: We build a mobile surveillance robot that streams video in real time and responds to speech so a user can monitor and steer it from a phone or browser. The system uses two Raspberry Pi 4 units: a front unit on a differential drive base with camera, mic, and speaker, and a central unit that serves the live feed and runs perception. Video is sent with FFmpeg. Objects in the scene are detected using YOLOv3 to support navigation and event awareness. For voice interaction, we use Python libraries for speech recognition, multilingual translation, and text-to-speech, so the robot can take spoken commands and read back responses in the requested language. A Kinect RGB-D sensor provides visual input and obstacle cues. In indoor tests the robot detects common objects at interactive frame rates on CPU, recognises commands reliably, and translates them to actions without manual control. The design relies on off-the-shelf hardware and open software, making it easy to reproduce. We discuss limits and practical extensions, including sensor fusion with ultrasonic range data, GPU acceleration, and adding face and text recognition.</summary>
    <category term="cs.RO"/>
    <category term="cs.AI"/>
    <category term="cs.CV"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Kshitij Kavimandan, Pooja Mangal, Devanshi Mehta</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13328v1</id>
    <title>A Dual-Attention Graph Network for fMRI Data Classification</title>
    <updated>2025-08-20T04:00:19.899642+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13328" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13328v1 Announce Type: cross 
Abstract: Understanding the complex neural activity dynamics is crucial for the development of the field of neuroscience. Although current functional MRI classification approaches tend to be based on static functional connectivity or cannot capture spatio-temporal relationships comprehensively, we present a new framework that leverages dynamic graph creation and spatiotemporal attention mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in this research dynamically infers functional brain connectivity in each time interval using transformer-based attention mechanisms, enabling the model to selectively focus on crucial brain regions and time segments. By constructing time-varying graphs that are then processed with Graph Convolutional Networks (GCNs) and transformers, our method successfully captures both localized interactions and global temporal dependencies. Evaluated on the subset of ABIDE dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint modeling of dynamic connectivity and spatio-temporal context for fMRI classification. The core novelty arises from (1) attention-driven dynamic graph creation that learns temporal brain region interactions and (2) hierarchical spatio-temporal feature fusion through GCNtransformer fusion.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
    <dc:creator>Amirali Arbab, Zeinab Davarani, Mehran Safayani</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13355v1</id>
    <title>Counterfactual Probabilistic Diffusion with Expert Models</title>
    <updated>2025-08-20T04:00:19.899583+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13355" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13355v1 Announce Type: cross 
Abstract: Predicting counterfactual distributions in complex dynamical systems is essential for scientific modeling and decision-making in domains such as public health and medicine. However, existing methods often rely on point estimates or purely data-driven models, which tend to falter under data scarcity. We propose a time series diffusion-based framework that incorporates guidance from imperfect expert models by extracting high-level signals to serve as structured priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and data-driven approaches, enabling more reliable and interpretable causal inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations, synthetic pharmacological dynamics, and real-world case studies, demonstrating that it consistently outperforms strong baselines in both point prediction and distributional accuracy.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <category term="stat.ME"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Wenhao Mu, Zhi Cao, Mehmed Uludag, Alexander Rodr\'iguez</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13358v1</id>
    <title>Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT</title>
    <updated>2025-08-20T04:00:19.899530+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13358" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13358v1 Announce Type: cross 
Abstract: This paper tackles several challenges that arise when integrating Automatic Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device streaming speech translation. Although state-of-the-art ASR systems based on Recurrent Neural Network Transducers (RNN-T) can perform real-time transcription, achieving streaming translation in real-time remains a significant challenge. To address this issue, we propose a simultaneous translation approach that effectively balances translation quality and latency. We also investigate efficient integration of ASR and MT, leveraging linguistic cues generated by the ASR system to manage context and utilizing efficient beam-search pruning techniques such as time-out and forced finalization to maintain system's real-time factor. We apply our approach to an on-device bilingual conversational speech translation and demonstrate that our techniques outperform baselines in terms of latency and quality. Notably, our technique narrows the quality gap with non-streaming translation systems, paving the way for more accurate and efficient real-time speech translation.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Zeeshan Ahmed, Frank Seide, Niko Moritz, Ju Lin, Ruiming Xie, Simone Merello, Zhe Liu, Christian Fuegen</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13376v1</id>
    <title>Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts</title>
    <updated>2025-08-20T04:00:19.899476+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13376" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13376v1 Announce Type: cross 
Abstract: ASR systems often struggle with maintaining syntactic and semantic accuracy in long audio transcripts, impacting tasks like Named Entity Recognition (NER), capitalization, and punctuation. We propose a novel approach that enhances ASR by distilling contextual knowledge from LLaMA models into Whisper. Our method uses two strategies: (1) token level distillation with optimal transport to align dimensions and sequence lengths, and (2) representation loss minimization between sentence embeddings of Whisper and LLaMA, blending syntax and semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long audios and rich entities demonstrate significant improvements in Word Error Rate (WER), NER, capitalization, and punctuation success. By introducing novel NER metrics and exploring semantics aware ASR, our work highlights the value of integrating linguistic context into transcription, setting a foundation for robust, context-aware ASR in longform speech.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <dc:creator>Duygu Altinok</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13382v1</id>
    <title>Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis</title>
    <updated>2025-08-20T04:00:19.899422+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13382" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13382v1 Announce Type: cross 
Abstract: We present Datarus-R1-14B, a 14 B-parameter open-weights language model fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and graduate-level problem solver. Datarus is trained not on isolated question-answer pairs but on full analytical trajectories including reasoning steps, code execution, error traces, self-corrections, and final conclusions, all captured in a ReAct-style notebook format spanning finance, medicine, numerical analysis, and other quantitative domains. Our training pipeline combines (i) a trajectory-centric synthetic data generator that yielded 144 000 tagged notebook episodes, (ii) a dual-reward framework blending a lightweight tag-based structural signal with a Hierarchical Reward Model (HRM) that scores both single-step soundness and end-to-end coherence, and (iii) a memory-optimized implementation of Group Relative Policy Optimization (GRPO) featuring KV-cache reuse, sequential generation, and reference-model sharding. A cosine curriculum smoothly shifts emphasis from structural fidelity to semantic depth, reducing the format collapse and verbosity that often plague RL-aligned LLMs. A central design choice in Datarus is it dual reasoning interface. In agentic mode the model produces ReAct-tagged steps that invoke Python tools to execute real code; in reflection mode it outputs compact Chain-of-Thought (CoT) traces delimited by &lt;think&gt; and &lt;answer&gt; tags. On demanding postgraduate-level problems, Datarus exhibits an "AHA-moment" pattern: it sketches hypotheses, revises them once or twice, and converges avoiding the circular, token-inflating loops common to contemporary systems. Across standard public benchmarks Datarus surpasses similar size models and even reaches the level of larger reasoning models such as QwQ-32B achieving up to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting 18-49% fewer tokens per solution.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Ayoub Ben Chaliah, Hela Dellagi</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13406v1</id>
    <title>Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp</title>
    <updated>2025-08-20T04:00:19.899366+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13406" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13406v1 Announce Type: cross 
Abstract: This study presents a quantitative framework for evaluating the spatial concordance between clinically defined seizure onset zones (SOZs) and statistically anomalous channels identified through time-frequency analysis of chirp events. The proposed pipeline employs a two-step methodology: (1) Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with adaptive neighborhood selection identifies anomalous channels based on spectro-temporal features of chirp (Onset frequency, offset frequency, and temporal duration); and (2) Spatial Correlation Analysis, which computes both exact co-occurrence metrics and weighted index similarity, incorporating hemispheric congruence and electrode proximity. Key findings demonstrate that the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects outliers, with index matching (weighted by channel proximity) outperforming exact matching in SOZ localization. Performance metrics (precision, recall, F1) were highest for seizure-free patients (Index Precision mean: 0.903) and those with successful surgical outcomes (Index Precision mean: 0.865), whereas failure cases exhibited lower concordance (Index Precision mean: 0.460). The key takeaway is that chirp-based outlier detection, combined with weighted spatial metrics, provides a complementary method for SOZ localization, particularly in patients with successful surgical outcomes.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Nooshin Bahador, Milad Lankarany</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13423v1</id>
    <title>AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System</title>
    <updated>2025-08-20T04:00:19.899311+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13423" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13423v1 Announce Type: cross 
Abstract: In recent years, recommendation systems have evolved from providing a single list of recommendations to offering a comprehensive suite of topic focused services. To better accomplish this task, conversational recommendation systems (CRS) have progressed from basic retrieval augmented LLM generation to agentic systems with advanced reasoning and self correction capabilities. However, agentic systems come with notable response latency, a longstanding challenge for conversational recommendation systems. To balance the trade off between handling complex queries and minimizing latency, we propose AdaptJobRec, the first conversational job recommendation system that leverages autonomous agent to integrate personalized recommendation algorithm tools. The system employs a user query complexity identification mechanism to minimize response latency. For straightforward queries, the agent directly selects the appropriate tool for rapid responses. For complex queries, the agent uses the memory processing module to filter chat history for relevant content, then passes the results to the intelligent task decomposition planner, and finally executes the tasks using personalized recommendation tools. Evaluation on Walmart's real world career recommendation scenarios demonstrates that AdaptJobRec reduces average response latency by up to 53.3% compared to competitive baselines, while significantly improving recommendation accuracy.</summary>
    <category term="cs.IR"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Qixin Wang, Dawei Wang, Kun Chen, Yaowei Hu, Puneet Girdhar, Ruoteng Wang, Aadesh Gupta, Chaitanya Devella, Wenlai Guo, Shangwen Huang, Bachir Aoun, Greg Hayworth, Han Li, Xintao Wu</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13426v1</id>
    <title>ALIGN: Word Association Learning for Cross-Cultural Generalization in Large Language Models</title>
    <updated>2025-08-20T04:00:19.899254+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13426" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13426v1 Announce Type: cross 
Abstract: As large language models (LLMs) increasingly mediate cross-cultural communication, their behavior still reflects the distributional bias of the languages and viewpoints that are over-represented in their pre-training corpora. Yet, it remains a challenge to model and align culture due to limited cultural knowledge and a lack of exploration into effective learning approaches. We introduce a cost-efficient, cognitively grounded remedy: parameter-efficient fine-tuning on native speakers' free word-association norms, which encode implicit cultural schemas. Leveraging English-US and Mandarin associations from the Small-World-of-Words project, we adapt Llama-3.1-8B and Qwen-2.5-7B via supervised fine-tuning (SFT) and PPO-based preference optimization. SFT boosts held-out association Precision at 5 by 16-20% in English and 43-165% in Mandarin, lifts median concreteness by +0.20, and attains human-level valence and arousal. These lexical gains transfer: on World-Values-Survey questions, fine-tuned models shift answer distributions toward the target culture, and on a 50-item high-tension subset, Qwen's Chinese-aligned responses double while Llama's US bias drops by one-third. Our 7-8B models rival or beat vanilla 70B baselines, showing that a few million culture-grounded associations can instill value alignment without costly retraining. Our work highlights both the promise and the need for future research grounded in human cognition in improving cultural alignment in AI models.</summary>
    <category term="cs.CL"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
    <dc:creator>Chunhua Liu, Kabir Manandhar Shrestha, Sukai Huang</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13428v1</id>
    <title>Mitigating Easy Option Bias in Multiple-Choice Question Answering</title>
    <updated>2025-08-20T04:00:19.899197+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13428" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13428v1 Announce Type: cross 
Abstract: In this early study, we observe an Easy-Options Bias (EOB) issue in some multiple-choice Visual Question Answering (VQA) benchmarks such as MMStar, RealWorldQA, SEED-Bench, Next-QA, STAR benchmark and Video-MME. This bias allows vision-language models (VLMs) to select the correct answer using only the vision (V) and options (O) as inputs, without the need for the question (Q). Through grounding experiments, we attribute the bias to an imbalance in visual relevance: the correct answer typically aligns more closely with the visual contents than the negative options in feature space, creating a shortcut for VLMs to infer the answer via simply vision-option similarity matching. To fix this, we introduce GroundAttack, a toolkit that automatically generates hard negative options as visually plausible as the correct answer. We apply it to the NExT-QA and MMStar datasets, creating new EOB-free annotations. On these EOB-free annotations, current VLMs approach to random accuracies under (V+O) settings, and drop to non-saturated accuracies under (V+Q+O) settings, providing a more realistic evaluation of VLMs' QA ability. Codes and new annotations will be released soon.</summary>
    <category term="cs.CV"/>
    <category term="cs.AI"/>
    <category term="cs.MM"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Hao Zhang, Chen Li, Basura Fernando</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13429v1</id>
    <title>AlphaX: An AI-Based Value Investing Strategy for the Brazilian Stock Market</title>
    <updated>2025-08-20T04:00:19.899141+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13429" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13429v1 Announce Type: cross 
Abstract: Autonomous trading strategies have been a subject of research within the field of artificial intelligence (AI) for aconsiderable period. Various AI techniques have been explored to develop autonomous agents capable of trading financial assets. These approaches encompass traditional methods such as neural networks, fuzzy logic, and reinforcement learning, as well as more recent advancements, including deep neural networks and deep reinforcement learning. Many developers report success in creating strategies that exhibit strong performance during simulations using historical price data, a process commonly referred to as backtesting. However, when these strategies are deployed in real markets, their performance often deteriorates, particularly in terms of risk-adjusted returns. In this study, we propose an AI-based strategy inspired by a classical investment paradigm: Value Investing. Financial AI models are highly susceptible to lookahead bias and other forms of bias that can significantly inflate performance in backtesting compared to live trading conditions. To address this issue, we conducted a series of computational simulations while controlling for these biases, thereby reducing the risk of overfitting. Our results indicate that the proposed approach outperforms major Brazilian market benchmarks. Moreover, the strategy, named AlphaX, demonstrated superior performance relative to widely used technical indicators such as the Relative Strength Index (RSI) and Money Flow Index (MFI), with statistically significant results. Finally, we discuss several open challenges and highlight emerging technologies in qualitative analysis that may contribute to the development of a comprehensive AI-based Value Investing framework in the future</summary>
    <category term="q-fin.CP"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Paulo Andr\'e Lima de Castro</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13434v1</id>
    <title>EventTSF: Event-Aware Non-Stationary Time Series Forecasting</title>
    <updated>2025-08-20T04:00:19.899079+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13434" rel="alternate" type="text/html"/>
    <summary>arXiv:2508.13434v1 Announce Type: cross 
Abstract: Time series forecasting plays a vital role in critical domains like energy and transportation, where non-stationary dynamics are deeply intertwined with events in other modalities such as texts. However, incorporating natural language-based external events to improve non-stationary forecasting remains largely unexplored, as most approaches still rely on a single modality, resulting in limited contextual knowledge and model underperformance. Enabling fine-grained multimodal interactions between temporal and textual data is challenged by three fundamental issues: (1) the difficulty of fine-grained synchronization between time-varying discrete textual events and continuous time series; (2) the inherent temporal uncertainty introduced by textual semantics; and (3) the misalignment between textual event embeddings and multi-resolution temporal patterns. In this work, we address these challenges by introducing event-aware non-stationary time series forecasting (EventTSF), an autoregressive generation framework that integrates historical time series with textual events to make subsequent forecasts. Specifically, EventTSF uses autoregressive diffusion with flow matching at each step to capture nuanced temporal-event interactions. To handle event-induced uncertainty, flow matching timesteps are adaptively controlled according to event semantic signals. The underlying denoiser employs a multimodal U-shaped diffusion transformer that efficiently fuses temporal and textual modalities across different resolutions. Extensive experiments on 8 synthetic and real-world datasets show that EventTSF outperforms 12 baselines across diverse event-aware non-stationary time series forecasting scenarios, achieving substantial improvements of 10.7% higher forecasting accuracy and $1.13\times$ faster training efficiency.</summary>
    <category term="cs.LG"/>
    <category term="cs.AI"/>
    <published>2025-08-20T00:00:00-04:00</published>
    <arxiv:announce_type>cross</arxiv:announce_type>
    <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
    <dc:creator>Yunfeng Ge, Ming Jin, Yiji Zhao, Hongyan Li, Bo Du, Chang Xu, Shirui Pan</dc:creator>
  </entry>
  <entry>
    <id>oai:arXiv.org:2508.13435v1</id>
    <title>SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer</title>
    <updated>2025-08-20T04:00:19.899011+00:00</updated>
    <link href="https://arxiv.org/abs/2508.13435" rel="alternate" type="text/html"/>